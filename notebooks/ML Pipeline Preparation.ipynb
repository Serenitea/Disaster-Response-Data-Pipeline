{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cache-magic\n",
      "  Downloading cache-magic-1.0.4.tar.gz (7.0 kB)\n",
      "Collecting astunparse\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: IPython in c:\\programdata\\anaconda3\\lib\\site-packages (from cache-magic) (7.13.0)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse->cache-magic) (0.34.2)\n",
      "Requirement already satisfied: six<2.0,>=1.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse->cache-magic) (1.14.0)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->cache-magic) (0.15.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->cache-magic) (46.2.0.post20200511)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->cache-magic) (4.3.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->cache-magic) (3.0.4)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->cache-magic) (0.4.3)\n",
      "Requirement already satisfied: pygments in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->cache-magic) (2.6.1)\n",
      "Requirement already satisfied: backcall in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->cache-magic) (0.1.0)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->cache-magic) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->cache-magic) (0.7.5)\n",
      "Requirement already satisfied: parso>=0.5.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from jedi>=0.10->IPython->cache-magic) (0.5.2)\n",
      "Requirement already satisfied: ipython-genutils in c:\\programdata\\anaconda3\\lib\\site-packages (from traitlets>=4.2->IPython->cache-magic) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->cache-magic) (0.1.9)\n",
      "Building wheels for collected packages: cache-magic\n",
      "  Building wheel for cache-magic (setup.py): started\n",
      "  Building wheel for cache-magic (setup.py): finished with status 'done'\n",
      "  Created wheel for cache-magic: filename=cache_magic-1.0.4-py3-none-any.whl size=6703 sha256=e9ef3193b25191edfea94b00e685ecc725cdf2ee8f874cabec792caafd04ab1c\n",
      "  Stored in directory: c:\\users\\zhouc\\appdata\\local\\pip\\cache\\wheels\\24\\16\\f2\\016dbddf24f703cf51ad82bb88ca3a77458b20199acd3a5590\n",
      "Successfully built cache-magic\n",
      "Installing collected packages: astunparse, tabulate, cache-magic\n",
      "Successfully installed astunparse-1.6.3 cache-magic-1.0.4 tabulate-0.8.7\n"
     ]
    }
   ],
   "source": [
    "!pip install cache-magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_count = (df.iloc[:, 4:] != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "related                   19906\n",
       "request                    4474\n",
       "offer                       118\n",
       "aid_related               10860\n",
       "medical_help               2084\n",
       "medical_products           1313\n",
       "search_and_rescue           724\n",
       "security                    471\n",
       "military                    860\n",
       "water                      1672\n",
       "food                       2923\n",
       "shelter                    2314\n",
       "clothing                    405\n",
       "money                       604\n",
       "missing_people              298\n",
       "refugees                    875\n",
       "death                      1194\n",
       "other_aid                  3446\n",
       "infrastructure_related     1705\n",
       "transport                  1201\n",
       "buildings                  1333\n",
       "electricity                 532\n",
       "tools                       159\n",
       "hospitals                   283\n",
       "shops                       120\n",
       "aid_centers                 309\n",
       "other_infrastructure       1151\n",
       "weather_related            7297\n",
       "floods                     2155\n",
       "storm                      2443\n",
       "fire                        282\n",
       "earthquake                 2455\n",
       "cold                        530\n",
       "other_weather              1376\n",
       "direct_report              5075\n",
       "dtype: int64"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new value for variable 'cache1'\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function tokenize at 0x0000022E4B4A5CA8>: it's not the same object as __main__.tokenize",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-388-32dff36fd725>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cache'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cache1 = model_cv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2315\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2316\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2317\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2318\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-127>\u001b[0m in \u001b[0;36mcache\u001b[1;34m(self, line)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\cache_magic\\__init__.py\u001b[0m in \u001b[0;36mcache\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0mparameter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             \u001b[0mCacheCall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparameter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCacheCallException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\cache_magic\\__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, version, reset, var_name, var_value, show_all, set_debug)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0mvar_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m                 var_value)\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\cache_magic\\__init__.py\u001b[0m in \u001b[0;36m_create_new_value\u001b[1;34m(self, shell, var_folder_path, var_data_path, var_info_path, version, var_name, var_value)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# store the result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_data_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m             \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         info = dict(expression_hash=var_value,\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <function tokenize at 0x0000022E4B4A5CA8>: it's not the same object as __main__.tokenize"
     ]
    }
   ],
   "source": [
    "%cache cache1 = model_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle dict_keys objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-376-edf038076cd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdill\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'notebook_env.db'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dill\\_dill.py\u001b[0m in \u001b[0;36mdump_session\u001b[1;34m(filename, main, byref, **kwds)\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[0mpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recurse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;31m# disable pickling recursion for globals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m  \u001b[1;31m# is best indicator of when pickling a session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m         \u001b[0mpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# If newly opened file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dill\\_dill.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mPicklingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m             \u001b[0mStockPickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# clear record of 'recursion-sensitive' pickled objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_framing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    502\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Call unbound method with explicit self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dill\\_dill.py\u001b[0m in \u001b[0;36msave_module\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1293\u001b[0m                 + [\"__builtins__\", \"__loader__\"]]\n\u001b[0;32m   1294\u001b[0m             pickler.save_reduce(_import_module, (obj.__name__,), obj=obj,\n\u001b[1;32m-> 1295\u001b[1;33m                                 state=_main_dict)\n\u001b[0m\u001b[0;32m   1296\u001b[0m             \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"# M1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m             \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    663\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    502\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Call unbound method with explicit self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dill\\_dill.py\u001b[0m in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;31m# we only care about session the first pass thru\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m             \u001b[0mpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m         \u001b[0mStockPickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"# D2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    883\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m                     \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m                     \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    502\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Call unbound method with explicit self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dill\\_dill.py\u001b[0m in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;31m# we only care about session the first pass thru\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m             \u001b[0mpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m         \u001b[0mStockPickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"# D2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    883\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m                     \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m                     \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[0mreduce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__reduce_ex__\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m                 \u001b[0mrv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[0mreduce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__reduce__\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't pickle dict_keys objects"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "dill.dump_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change if needed\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "import sys\n",
    "import cache_magic\n",
    "\n",
    "#machine learning\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer, classification_report, fbeta_score\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "#NLP\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///../data/disaster_response.db')\n",
    "df = pd.read_sql_table(table_name='message_categories', con=engine)\n",
    "X = df['message']\n",
    "Y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                            0\n",
       "message                       0\n",
       "original                  15990\n",
       "genre                         0\n",
       "related                       0\n",
       "request                       0\n",
       "offer                         0\n",
       "aid_related                   0\n",
       "medical_help                  0\n",
       "medical_products              0\n",
       "search_and_rescue             0\n",
       "security                      0\n",
       "military                      0\n",
       "water                         0\n",
       "food                          0\n",
       "shelter                       0\n",
       "clothing                      0\n",
       "money                         0\n",
       "missing_people                0\n",
       "refugees                      0\n",
       "death                         0\n",
       "other_aid                     0\n",
       "infrastructure_related        0\n",
       "transport                     0\n",
       "buildings                     0\n",
       "electricity                   0\n",
       "tools                         0\n",
       "hospitals                     0\n",
       "shops                         0\n",
       "aid_centers                   0\n",
       "other_infrastructure          0\n",
       "weather_related               0\n",
       "floods                        0\n",
       "storm                         0\n",
       "fire                          0\n",
       "earthquake                    0\n",
       "cold                          0\n",
       "other_weather                 0\n",
       "direct_report                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Weather update - a cold front from Cuba that c...\n",
       "1                  Is the Hurricane over or is it not over\n",
       "2                          Looking for someone but no name\n",
       "3        UN reports Leogane 80-90 destroyed. Only Hospi...\n",
       "4        says: west side of Haiti, rest of the country ...\n",
       "                               ...                        \n",
       "26023    The training demonstrated how to enhance micro...\n",
       "26024    A suitable candidate has been selected and OCH...\n",
       "26025    Proshika, operating in Cox's Bazar municipalit...\n",
       "26026    Some 2,000 women protesting against the conduc...\n",
       "26027    A radical shift in thinking came about as a re...\n",
       "Name: message, Length: 26028, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>water</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26023</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26024</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26025</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26026</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26027</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26028 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0            1        0      0            0             0                 0   \n",
       "1            1        0      0            1             0                 0   \n",
       "2            1        0      0            0             0                 0   \n",
       "3            1        1      0            1             0                 1   \n",
       "4            1        0      0            0             0                 0   \n",
       "...        ...      ...    ...          ...           ...               ...   \n",
       "26023        0        0      0            0             0                 0   \n",
       "26024        0        0      0            0             0                 0   \n",
       "26025        1        0      0            0             0                 0   \n",
       "26026        1        0      0            1             0                 0   \n",
       "26027        1        0      0            0             0                 0   \n",
       "\n",
       "       search_and_rescue  security  military  water  ...  aid_centers  \\\n",
       "0                      0         0         0      0  ...            0   \n",
       "1                      0         0         0      0  ...            0   \n",
       "2                      0         0         0      0  ...            0   \n",
       "3                      0         0         0      0  ...            0   \n",
       "4                      0         0         0      0  ...            0   \n",
       "...                  ...       ...       ...    ...  ...          ...   \n",
       "26023                  0         0         0      0  ...            0   \n",
       "26024                  0         0         0      0  ...            0   \n",
       "26025                  0         0         0      0  ...            0   \n",
       "26026                  0         0         1      0  ...            0   \n",
       "26027                  0         0         0      0  ...            0   \n",
       "\n",
       "       other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                         0                0       0      0     0           0   \n",
       "1                         0                1       0      1     0           0   \n",
       "2                         0                0       0      0     0           0   \n",
       "3                         0                0       0      0     0           0   \n",
       "4                         0                0       0      0     0           0   \n",
       "...                     ...              ...     ...    ...   ...         ...   \n",
       "26023                     0                0       0      0     0           0   \n",
       "26024                     0                0       0      0     0           0   \n",
       "26025                     0                0       0      0     0           0   \n",
       "26026                     0                0       0      0     0           0   \n",
       "26027                     0                0       0      0     0           0   \n",
       "\n",
       "       cold  other_weather  direct_report  \n",
       "0         0              0              0  \n",
       "1         0              0              0  \n",
       "2         0              0              0  \n",
       "3         0              0              0  \n",
       "4         0              0              0  \n",
       "...     ...            ...            ...  \n",
       "26023     0              0              0  \n",
       "26024     0              0              0  \n",
       "26025     0              0              0  \n",
       "26026     0              0              0  \n",
       "26027     0              0              0  \n",
       "\n",
       "[26028 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    '''\n",
    "    IN: \n",
    "        raw text for tokenizing via the following steps: \n",
    "            - normalized, punctuation removed, stop words removed, stemmed, and lemmatized\n",
    "    OUT:\n",
    "        tokenized text\n",
    "    '''\n",
    "    #Normalize text and remove punctuation\n",
    "    normalized_txt = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    #tokenize text\n",
    "    words = word_tokenize(normalized_txt)\n",
    " \n",
    "    #lemmatize\n",
    "    words = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
    "    \n",
    "    #Reduce words to their stems\n",
    "    words = [PorterStemmer().stem(w) for w in words]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting pipeline\n",
    "def pipeline_model():\n",
    "    pipeline = Pipeline([('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', MultiOutputClassifier(RandomForestClassifier()))])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'vect', 'tfidf', 'clf', 'vect__analyzer', 'vect__binary', 'vect__decode_error', 'vect__dtype', 'vect__encoding', 'vect__input', 'vect__lowercase', 'vect__max_df', 'vect__max_features', 'vect__min_df', 'vect__ngram_range', 'vect__preprocessor', 'vect__stop_words', 'vect__strip_accents', 'vect__token_pattern', 'vect__tokenizer', 'vect__vocabulary', 'tfidf__norm', 'tfidf__smooth_idf', 'tfidf__sublinear_tf', 'tfidf__use_idf', 'clf__estimator__bootstrap', 'clf__estimator__ccp_alpha', 'clf__estimator__class_weight', 'clf__estimator__criterion', 'clf__estimator__max_depth', 'clf__estimator__max_features', 'clf__estimator__max_leaf_nodes', 'clf__estimator__max_samples', 'clf__estimator__min_impurity_decrease', 'clf__estimator__min_impurity_split', 'clf__estimator__min_samples_leaf', 'clf__estimator__min_samples_split', 'clf__estimator__min_weight_fraction_leaf', 'clf__estimator__n_estimators', 'clf__estimator__n_jobs', 'clf__estimator__oob_score', 'clf__estimator__random_state', 'clf__estimator__verbose', 'clf__estimator__warm_start', 'clf__estimator', 'clf__n_jobs'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [6, 26028]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-31484f6e99b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2116\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2118\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2120\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \"\"\"\n\u001b[0;32m    247\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 212\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [6, 26028]"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at...\n",
       "                                                                        ccp_alpha=0.0,\n",
       "                                                                        class_weight=None,\n",
       "                                                                        criterion='gini',\n",
       "                                                                        max_depth=None,\n",
       "                                                                        max_features='auto',\n",
       "                                                                        max_leaf_nodes=None,\n",
       "                                                                        max_samples=None,\n",
       "                                                                        min_impurity_decrease=0.0,\n",
       "                                                                        min_impurity_split=None,\n",
       "                                                                        min_samples_leaf=1,\n",
       "                                                                        min_samples_split=2,\n",
       "                                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                                        n_estimators=100,\n",
       "                                                                        n_jobs=None,\n",
       "                                                                        oob_score=False,\n",
       "                                                                        random_state=None,\n",
       "                                                                        verbose=0,\n",
       "                                                                        warm_start=False),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#make predictions\n",
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_report(Y_test, y_preds):\n",
    "    '''\n",
    "    Create a weighted averages summary dataframe for each label, \n",
    "    using the classification_report function \n",
    "    IN: \n",
    "        Y_test - array of actual values\n",
    "        y_preds - numpy array of predicted values\n",
    "    OUT df columns: precision,recall,f1-score,support\n",
    "    This is a performance metric reference from Github User: rebeccaebarnes\n",
    "    '''\n",
    "    results_dict = {}\n",
    "\n",
    "    for pred, label, col in zip(y_preds.transpose(), Y_test.values.transpose(), Y_test.columns):\n",
    "        results_dict[col] = classification_report(label, pred, output_dict=True)\n",
    "        \n",
    "    weighted_avg = {}\n",
    "    for key in results_dict.keys():\n",
    "        weighted_avg[key] = results_dict[key]['weighted avg']\n",
    "\n",
    "    df_wavg = pd.DataFrame(weighted_avg).transpose()\n",
    "    return df_wavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_avg_report(df):\n",
    "    '''\n",
    "    OUT:\n",
    "        descriptive statistics for the created weighted averages summary df\n",
    "        upper and lower quantile df slices\n",
    "    '''\n",
    "    display(df['f1-score'].describe())\n",
    "    display('lowest quantile of f scores',df[df['f1-score'] <= df['f1-score'].quantile(0.25)]) # lowest quantile of f scores\n",
    "    #print(df.sort_values('f1-score').head(n = 10))\n",
    "    display('highest quantile of f scores', df[df['f1-score'] >= df['f1-score'].quantile(0.75)]) # highest quantile of f scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35.000000\n",
       "mean      0.931140\n",
       "std       0.057876\n",
       "min       0.771124\n",
       "25%       0.916096\n",
       "50%       0.944198\n",
       "75%       0.971679\n",
       "max       0.994010\n",
       "Name: f1-score, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'lowest quantile of f scores'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.798599</td>\n",
       "      <td>0.806209</td>\n",
       "      <td>0.771124</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.893981</td>\n",
       "      <td>0.896266</td>\n",
       "      <td>0.882489</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.784650</td>\n",
       "      <td>0.783157</td>\n",
       "      <td>0.778731</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.902344</td>\n",
       "      <td>0.918549</td>\n",
       "      <td>0.883507</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.922070</td>\n",
       "      <td>0.926387</td>\n",
       "      <td>0.914761</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.845730</td>\n",
       "      <td>0.873060</td>\n",
       "      <td>0.817647</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.875334</td>\n",
       "      <td>0.935147</td>\n",
       "      <td>0.904252</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.875941</td>\n",
       "      <td>0.877363</td>\n",
       "      <td>0.872271</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.862917</td>\n",
       "      <td>0.861380</td>\n",
       "      <td>0.836987</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision    recall  f1-score  support\n",
       "related                  0.798599  0.806209  0.771124   6507.0\n",
       "request                  0.893981  0.896266  0.882489   6507.0\n",
       "aid_related              0.784650  0.783157  0.778731   6507.0\n",
       "medical_help             0.902344  0.918549  0.883507   6507.0\n",
       "food                     0.922070  0.926387  0.914761   6507.0\n",
       "other_aid                0.845730  0.873060  0.817647   6507.0\n",
       "infrastructure_related   0.875334  0.935147  0.904252   6507.0\n",
       "weather_related          0.875941  0.877363  0.872271   6507.0\n",
       "direct_report            0.862917  0.861380  0.836987   6507.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'highest quantile of f scores'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.992025</td>\n",
       "      <td>0.996004</td>\n",
       "      <td>0.994010</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.983620</td>\n",
       "      <td>0.985708</td>\n",
       "      <td>0.980129</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.989809</td>\n",
       "      <td>0.989703</td>\n",
       "      <td>0.984731</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.979456</td>\n",
       "      <td>0.981405</td>\n",
       "      <td>0.973295</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.987743</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.990789</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.978296</td>\n",
       "      <td>0.989089</td>\n",
       "      <td>0.983663</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.989271</td>\n",
       "      <td>0.994621</td>\n",
       "      <td>0.991939</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.977992</td>\n",
       "      <td>0.988935</td>\n",
       "      <td>0.983433</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.977991</td>\n",
       "      <td>0.988781</td>\n",
       "      <td>0.983356</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                precision    recall  f1-score  support\n",
       "offer            0.992025  0.996004  0.994010   6507.0\n",
       "clothing         0.983620  0.985708  0.980129   6507.0\n",
       "missing_people   0.989809  0.989703  0.984731   6507.0\n",
       "electricity      0.979456  0.981405  0.973295   6507.0\n",
       "tools            0.987743  0.993853  0.990789   6507.0\n",
       "hospitals        0.978296  0.989089  0.983663   6507.0\n",
       "shops            0.989271  0.994621  0.991939   6507.0\n",
       "aid_centers      0.977992  0.988935  0.983433   6507.0\n",
       "fire             0.977991  0.988781  0.983356   6507.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weighted_avg_report(df_wavg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.798599</td>\n",
       "      <td>0.806209</td>\n",
       "      <td>0.771124</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.893981</td>\n",
       "      <td>0.896266</td>\n",
       "      <td>0.882489</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.992025</td>\n",
       "      <td>0.996004</td>\n",
       "      <td>0.994010</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.784650</td>\n",
       "      <td>0.783157</td>\n",
       "      <td>0.778731</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.902344</td>\n",
       "      <td>0.918549</td>\n",
       "      <td>0.883507</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.946887</td>\n",
       "      <td>0.949900</td>\n",
       "      <td>0.929101</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.972233</td>\n",
       "      <td>0.971415</td>\n",
       "      <td>0.958197</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.966493</td>\n",
       "      <td>0.979407</td>\n",
       "      <td>0.969668</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.951597</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.951062</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.946390</td>\n",
       "      <td>0.948210</td>\n",
       "      <td>0.933750</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.922070</td>\n",
       "      <td>0.926387</td>\n",
       "      <td>0.914761</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.927412</td>\n",
       "      <td>0.932073</td>\n",
       "      <td>0.917431</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.983620</td>\n",
       "      <td>0.985708</td>\n",
       "      <td>0.980129</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.970125</td>\n",
       "      <td>0.974950</td>\n",
       "      <td>0.963854</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.989809</td>\n",
       "      <td>0.989703</td>\n",
       "      <td>0.984731</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.948015</td>\n",
       "      <td>0.967727</td>\n",
       "      <td>0.952750</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.954218</td>\n",
       "      <td>0.959121</td>\n",
       "      <td>0.944198</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.845730</td>\n",
       "      <td>0.873060</td>\n",
       "      <td>0.817647</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.875334</td>\n",
       "      <td>0.935147</td>\n",
       "      <td>0.904252</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.947815</td>\n",
       "      <td>0.956816</td>\n",
       "      <td>0.940107</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.944068</td>\n",
       "      <td>0.948210</td>\n",
       "      <td>0.926983</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.979456</td>\n",
       "      <td>0.981405</td>\n",
       "      <td>0.973295</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.987743</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.990789</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.978296</td>\n",
       "      <td>0.989089</td>\n",
       "      <td>0.983663</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.989271</td>\n",
       "      <td>0.994621</td>\n",
       "      <td>0.991939</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.977992</td>\n",
       "      <td>0.988935</td>\n",
       "      <td>0.983433</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.915484</td>\n",
       "      <td>0.956508</td>\n",
       "      <td>0.935546</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.875941</td>\n",
       "      <td>0.877363</td>\n",
       "      <td>0.872271</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.952818</td>\n",
       "      <td>0.954049</td>\n",
       "      <td>0.947253</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.931800</td>\n",
       "      <td>0.937452</td>\n",
       "      <td>0.929327</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.977991</td>\n",
       "      <td>0.988781</td>\n",
       "      <td>0.983356</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.967129</td>\n",
       "      <td>0.968342</td>\n",
       "      <td>0.967192</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.979831</td>\n",
       "      <td>0.979407</td>\n",
       "      <td>0.970064</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.938046</td>\n",
       "      <td>0.949746</td>\n",
       "      <td>0.926304</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.862917</td>\n",
       "      <td>0.861380</td>\n",
       "      <td>0.836987</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision    recall  f1-score  support\n",
       "related                  0.798599  0.806209  0.771124   6507.0\n",
       "request                  0.893981  0.896266  0.882489   6507.0\n",
       "offer                    0.992025  0.996004  0.994010   6507.0\n",
       "aid_related              0.784650  0.783157  0.778731   6507.0\n",
       "medical_help             0.902344  0.918549  0.883507   6507.0\n",
       "medical_products         0.946887  0.949900  0.929101   6507.0\n",
       "search_and_rescue        0.972233  0.971415  0.958197   6507.0\n",
       "security                 0.966493  0.979407  0.969668   6507.0\n",
       "military                 0.951597  0.965576  0.951062   6507.0\n",
       "water                    0.946390  0.948210  0.933750   6507.0\n",
       "food                     0.922070  0.926387  0.914761   6507.0\n",
       "shelter                  0.927412  0.932073  0.917431   6507.0\n",
       "clothing                 0.983620  0.985708  0.980129   6507.0\n",
       "money                    0.970125  0.974950  0.963854   6507.0\n",
       "missing_people           0.989809  0.989703  0.984731   6507.0\n",
       "refugees                 0.948015  0.967727  0.952750   6507.0\n",
       "death                    0.954218  0.959121  0.944198   6507.0\n",
       "other_aid                0.845730  0.873060  0.817647   6507.0\n",
       "infrastructure_related   0.875334  0.935147  0.904252   6507.0\n",
       "transport                0.947815  0.956816  0.940107   6507.0\n",
       "buildings                0.944068  0.948210  0.926983   6507.0\n",
       "electricity              0.979456  0.981405  0.973295   6507.0\n",
       "tools                    0.987743  0.993853  0.990789   6507.0\n",
       "hospitals                0.978296  0.989089  0.983663   6507.0\n",
       "shops                    0.989271  0.994621  0.991939   6507.0\n",
       "aid_centers              0.977992  0.988935  0.983433   6507.0\n",
       "other_infrastructure     0.915484  0.956508  0.935546   6507.0\n",
       "weather_related          0.875941  0.877363  0.872271   6507.0\n",
       "floods                   0.952818  0.954049  0.947253   6507.0\n",
       "storm                    0.931800  0.937452  0.929327   6507.0\n",
       "fire                     0.977991  0.988781  0.983356   6507.0\n",
       "earthquake               0.967129  0.968342  0.967192   6507.0\n",
       "cold                     0.979831  0.979407  0.970064   6507.0\n",
       "other_weather            0.938046  0.949746  0.926304   6507.0\n",
       "direct_report            0.862917  0.861380  0.836987   6507.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_avg = {}\n",
    "for key in results_dict.keys():\n",
    "    weighted_avg[key] = results_dict[key]['weighted avg']\n",
    "\n",
    "df_wavg = pd.DataFrame(weighted_avg).transpose()\n",
    "df_wavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35.000000\n",
       "mean      0.931140\n",
       "std       0.057876\n",
       "min       0.771124\n",
       "25%       0.916096\n",
       "50%       0.944198\n",
       "75%       0.971679\n",
       "max       0.994010\n",
       "Name: f1-score, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wavg['f1-score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.798599</td>\n",
       "      <td>0.806209</td>\n",
       "      <td>0.771124</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.893981</td>\n",
       "      <td>0.896266</td>\n",
       "      <td>0.882489</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.784650</td>\n",
       "      <td>0.783157</td>\n",
       "      <td>0.778731</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.902344</td>\n",
       "      <td>0.918549</td>\n",
       "      <td>0.883507</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.922070</td>\n",
       "      <td>0.926387</td>\n",
       "      <td>0.914761</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.845730</td>\n",
       "      <td>0.873060</td>\n",
       "      <td>0.817647</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.875334</td>\n",
       "      <td>0.935147</td>\n",
       "      <td>0.904252</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.875941</td>\n",
       "      <td>0.877363</td>\n",
       "      <td>0.872271</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.862917</td>\n",
       "      <td>0.861380</td>\n",
       "      <td>0.836987</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision    recall  f1-score  support\n",
       "related                  0.798599  0.806209  0.771124   6507.0\n",
       "request                  0.893981  0.896266  0.882489   6507.0\n",
       "aid_related              0.784650  0.783157  0.778731   6507.0\n",
       "medical_help             0.902344  0.918549  0.883507   6507.0\n",
       "food                     0.922070  0.926387  0.914761   6507.0\n",
       "other_aid                0.845730  0.873060  0.817647   6507.0\n",
       "infrastructure_related   0.875334  0.935147  0.904252   6507.0\n",
       "weather_related          0.875941  0.877363  0.872271   6507.0\n",
       "direct_report            0.862917  0.861380  0.836987   6507.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wavg[df_wavg['f1-score'] <= df_wavg['f1-score'].quantile(0.25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.798599</td>\n",
       "      <td>0.806209</td>\n",
       "      <td>0.771124</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.784650</td>\n",
       "      <td>0.783157</td>\n",
       "      <td>0.778731</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.845730</td>\n",
       "      <td>0.873060</td>\n",
       "      <td>0.817647</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.862917</td>\n",
       "      <td>0.861380</td>\n",
       "      <td>0.836987</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.875941</td>\n",
       "      <td>0.877363</td>\n",
       "      <td>0.872271</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.893981</td>\n",
       "      <td>0.896266</td>\n",
       "      <td>0.882489</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.902344</td>\n",
       "      <td>0.918549</td>\n",
       "      <td>0.883507</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.875334</td>\n",
       "      <td>0.935147</td>\n",
       "      <td>0.904252</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.922070</td>\n",
       "      <td>0.926387</td>\n",
       "      <td>0.914761</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.927412</td>\n",
       "      <td>0.932073</td>\n",
       "      <td>0.917431</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision    recall  f1-score  support\n",
       "related                  0.798599  0.806209  0.771124   6507.0\n",
       "aid_related              0.784650  0.783157  0.778731   6507.0\n",
       "other_aid                0.845730  0.873060  0.817647   6507.0\n",
       "direct_report            0.862917  0.861380  0.836987   6507.0\n",
       "weather_related          0.875941  0.877363  0.872271   6507.0\n",
       "request                  0.893981  0.896266  0.882489   6507.0\n",
       "medical_help             0.902344  0.918549  0.883507   6507.0\n",
       "infrastructure_related   0.875334  0.935147  0.904252   6507.0\n",
       "food                     0.922070  0.926387  0.914761   6507.0\n",
       "shelter                  0.927412  0.932073  0.917431   6507.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wavg.sort_values('f1-score').head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.992025</td>\n",
       "      <td>0.996004</td>\n",
       "      <td>0.994010</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.983620</td>\n",
       "      <td>0.985708</td>\n",
       "      <td>0.980129</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.989809</td>\n",
       "      <td>0.989703</td>\n",
       "      <td>0.984731</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.979456</td>\n",
       "      <td>0.981405</td>\n",
       "      <td>0.973295</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.987743</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.990789</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.978296</td>\n",
       "      <td>0.989089</td>\n",
       "      <td>0.983663</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.989271</td>\n",
       "      <td>0.994621</td>\n",
       "      <td>0.991939</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.977992</td>\n",
       "      <td>0.988935</td>\n",
       "      <td>0.983433</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.977991</td>\n",
       "      <td>0.988781</td>\n",
       "      <td>0.983356</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                precision    recall  f1-score  support\n",
       "offer            0.992025  0.996004  0.994010   6507.0\n",
       "clothing         0.983620  0.985708  0.980129   6507.0\n",
       "missing_people   0.989809  0.989703  0.984731   6507.0\n",
       "electricity      0.979456  0.981405  0.973295   6507.0\n",
       "tools            0.987743  0.993853  0.990789   6507.0\n",
       "hospitals        0.978296  0.989089  0.983663   6507.0\n",
       "shops            0.989271  0.994621  0.991939   6507.0\n",
       "aid_centers      0.977992  0.988935  0.983433   6507.0\n",
       "fire             0.977991  0.988781  0.983356   6507.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wavg[df_wavg['f1-score'] >= df_wavg['f1-score'].quantile(0.75)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feats = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feats_counts = df_feats.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offer                     0.004534\n",
       "shops                     0.004610\n",
       "tools                     0.006109\n",
       "fire                      0.010834\n",
       "hospitals                 0.010873\n",
       "missing_people            0.011449\n",
       "aid_centers               0.011872\n",
       "clothing                  0.015560\n",
       "security                  0.018096\n",
       "cold                      0.020363\n",
       "electricity               0.020440\n",
       "money                     0.023206\n",
       "search_and_rescue         0.027816\n",
       "military                  0.033041\n",
       "refugees                  0.033618\n",
       "other_infrastructure      0.044222\n",
       "death                     0.045874\n",
       "transport                 0.046143\n",
       "medical_products          0.050446\n",
       "buildings                 0.051214\n",
       "other_weather             0.052866\n",
       "water                     0.064239\n",
       "infrastructure_related    0.065506\n",
       "medical_help              0.080068\n",
       "floods                    0.082795\n",
       "shelter                   0.088904\n",
       "storm                     0.093860\n",
       "earthquake                0.094321\n",
       "food                      0.112302\n",
       "other_aid                 0.132396\n",
       "request                   0.171892\n",
       "direct_report             0.194982\n",
       "weather_related           0.280352\n",
       "aid_related               0.417243\n",
       "related                   0.764792\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_feats_counts/df_feats.shape[0]).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "related                   0.771124\n",
       "aid_related               0.778731\n",
       "other_aid                 0.817647\n",
       "direct_report             0.836987\n",
       "weather_related           0.872271\n",
       "request                   0.882489\n",
       "medical_help              0.883507\n",
       "infrastructure_related    0.904252\n",
       "food                      0.914761\n",
       "shelter                   0.917431\n",
       "other_weather             0.926304\n",
       "buildings                 0.926983\n",
       "medical_products          0.929101\n",
       "storm                     0.929327\n",
       "water                     0.933750\n",
       "other_infrastructure      0.935546\n",
       "transport                 0.940107\n",
       "death                     0.944198\n",
       "floods                    0.947253\n",
       "military                  0.951062\n",
       "refugees                  0.952750\n",
       "search_and_rescue         0.958197\n",
       "money                     0.963854\n",
       "earthquake                0.967192\n",
       "security                  0.969668\n",
       "cold                      0.970064\n",
       "electricity               0.973295\n",
       "clothing                  0.980129\n",
       "fire                      0.983356\n",
       "aid_centers               0.983433\n",
       "hospitals                 0.983663\n",
       "missing_people            0.984731\n",
       "tools                     0.990789\n",
       "shops                     0.991939\n",
       "offer                     0.994010\n",
       "Name: f1-score, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wavg['f1-score'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26028"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feats.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                   dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                   lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                   ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                   strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                   tokenizer=<function tokenize at 0x0000022E4B4A5CA8>,\n",
       "                   vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       "  ('clf',\n",
       "   MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                          ccp_alpha=0.0,\n",
       "                                                          class_weight=None,\n",
       "                                                          criterion='gini',\n",
       "                                                          max_depth=None,\n",
       "                                                          max_features='auto',\n",
       "                                                          max_leaf_nodes=None,\n",
       "                                                          max_samples=None,\n",
       "                                                          min_impurity_decrease=0.0,\n",
       "                                                          min_impurity_split=None,\n",
       "                                                          min_samples_leaf=1,\n",
       "                                                          min_samples_split=2,\n",
       "                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                          n_estimators=100,\n",
       "                                                          n_jobs=None,\n",
       "                                                          oob_score=False,\n",
       "                                                          random_state=None,\n",
       "                                                          verbose=0,\n",
       "                                                          warm_start=False),\n",
       "                         n_jobs=None))],\n",
       " 'verbose': False,\n",
       " 'vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                 lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                 ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=<function tokenize at 0x0000022E4B4A5CA8>,\n",
       "                 vocabulary=None),\n",
       " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'clf': MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                        ccp_alpha=0.0,\n",
       "                                                        class_weight=None,\n",
       "                                                        criterion='gini',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features='auto',\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        max_samples=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        n_estimators=100,\n",
       "                                                        n_jobs=None,\n",
       "                                                        oob_score=False,\n",
       "                                                        random_state=None,\n",
       "                                                        verbose=0,\n",
       "                                                        warm_start=False),\n",
       "                       n_jobs=None),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'clf__estimator__bootstrap': True,\n",
       " 'clf__estimator__ccp_alpha': 0.0,\n",
       " 'clf__estimator__class_weight': None,\n",
       " 'clf__estimator__criterion': 'gini',\n",
       " 'clf__estimator__max_depth': None,\n",
       " 'clf__estimator__max_features': 'auto',\n",
       " 'clf__estimator__max_leaf_nodes': None,\n",
       " 'clf__estimator__max_samples': None,\n",
       " 'clf__estimator__min_impurity_decrease': 0.0,\n",
       " 'clf__estimator__min_impurity_split': None,\n",
       " 'clf__estimator__min_samples_leaf': 1,\n",
       " 'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__estimator__n_estimators': 100,\n",
       " 'clf__estimator__n_jobs': None,\n",
       " 'clf__estimator__oob_score': False,\n",
       " 'clf__estimator__random_state': None,\n",
       " 'clf__estimator__verbose': 0,\n",
       " 'clf__estimator__warm_start': False,\n",
       " 'clf__estimator': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                        criterion='gini', max_depth=None, max_features='auto',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                        n_jobs=None, oob_score=False, random_state=None,\n",
       "                        verbose=0, warm_start=False),\n",
       " 'clf__n_jobs': None}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range':[(1,2),(2,2)],\n",
    "            'clf__estimator__n_estimators':[50, 100]\n",
    "             }\n",
    "\n",
    "cv = GridSearchCV(estimator=pipeline, param_grid=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#grid search\n",
    "\n",
    "parameters = {'vect__min_df': [1, 5],\n",
    "              'tfidf__use_idf':[True, False],\n",
    "              'clf__estimator__n_estimators':[10, 25, 50, 100], \n",
    "              'clf__estimator__min_samples_split':[2, 5, 10]}\n",
    "\n",
    "model_cv = GridSearchCV(estimator=model, param_grid=parameters, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.218, total=  35.4s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   35.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.225, total=  36.4s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.225, total=  36.8s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.239, total=  35.8s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.235, total=  38.0s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.226, total=  34.5s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.224, total=  37.1s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.224, total=  35.0s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.233, total=  35.6s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.253, total=  38.2s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.215, total=  35.9s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.236, total=  36.8s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.221, total=  37.8s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.226, total=  37.1s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.231, total=  37.4s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.229, total=  33.5s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.237, total=  32.5s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.218, total=  32.5s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.232, total=  35.4s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.241, total=  33.0s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.229, total= 1.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.242, total= 1.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.217, total= 1.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.231, total= 1.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.244, total= 1.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.235, total= 1.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.247, total= 1.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.235, total= 1.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.245, total= 1.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.258, total= 1.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.221, total= 1.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.227, total= 1.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.223, total= 1.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.232, total= 1.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.237, total= 1.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.237, total= 1.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.238, total= 1.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.222, total=  57.8s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.241, total=  59.2s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.256, total= 1.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1, score=0.240, total= 2.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1, score=0.244, total= 2.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1, score=0.244, total= 2.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1, score=0.248, total= 2.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1, score=0.247, total= 2.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5, score=0.256, total= 1.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5, score=0.257, total= 1.9min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5, score=0.246, total= 1.9min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5, score=0.252, total= 1.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5, score=0.258, total= 1.9min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1, score=0.235, total= 2.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1, score=0.243, total= 2.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1, score=0.233, total= 2.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1, score=0.241, total= 1.9min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1, score=0.250, total= 2.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5, score=0.248, total= 1.7min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5, score=0.261, total= 1.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5, score=0.242, total= 1.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5, score=0.257, total= 1.7min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5, score=0.262, total= 1.7min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1, score=0.236, total= 3.7min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1, score=0.249, total= 3.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1, score=0.244, total= 3.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1, score=0.246, total= 3.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1, score=0.252, total= 3.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5, score=0.256, total= 3.4min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5, score=0.260, total= 3.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5, score=0.246, total= 3.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5, score=0.256, total= 3.4min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5, score=0.265, total= 3.4min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1, score=0.235, total= 3.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1, score=0.248, total= 3.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1, score=0.234, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1, score=0.246, total= 3.7min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1, score=0.250, total= 3.7min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5, score=0.247, total= 3.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5, score=0.257, total= 3.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5, score=0.249, total= 3.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5, score=0.249, total= 3.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5, score=0.266, total= 3.3min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.213, total=  34.2s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.223, total=  33.7s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.208, total=  34.5s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.215, total=  33.8s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.228, total=  35.0s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.229, total=  36.7s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.228, total=  33.7s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.232, total=  34.6s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.221, total=  33.8s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.228, total=  35.4s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.213, total=  31.6s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.223, total=  31.2s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.214, total=  31.2s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.217, total=  32.2s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.229, total=  33.4s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.216, total=  31.2s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.232, total=  32.5s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.222, total=  32.4s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.219, total=  32.1s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.231, total=  33.8s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.233, total= 1.0min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.232, total=  57.0s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.229, total=  58.0s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.238, total=  56.4s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.240, total=  57.5s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.238, total=  57.9s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.249, total=  56.7s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.236, total=  58.5s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.239, total=  56.5s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.246, total=  58.2s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.222, total=  55.5s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.236, total=  56.3s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.223, total=  55.2s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.228, total=  57.1s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.241, total=  55.6s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.245, total=  54.3s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.250, total=  52.8s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.245, total=  53.4s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.248, total=  52.2s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.254, total=  52.9s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1, score=0.229, total= 1.7min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1, score=0.244, total= 1.8min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1, score=0.230, total= 1.7min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1, score=0.239, total= 1.7min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1, score=0.242, total= 1.7min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5, score=0.250, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5, score=0.257, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5, score=0.245, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5, score=0.258, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5, score=0.261, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1, score=0.231, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1, score=0.237, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1, score=0.233, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1, score=0.236, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1, score=0.245, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5, score=0.249, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5, score=0.258, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5, score=0.238, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5, score=0.250, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5, score=0.255, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1, score=0.235, total= 3.1min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1, score=0.243, total= 3.1min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1, score=0.239, total= 3.1min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1, score=0.241, total= 3.0min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1, score=0.259, total= 3.2min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5, score=0.250, total= 3.1min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5, score=0.257, total= 3.1min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5, score=0.247, total= 3.1min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5, score=0.256, total= 3.1min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5, score=0.268, total= 3.1min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1, score=0.240, total= 3.1min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1, score=0.243, total= 3.1min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1, score=0.240, total= 3.0min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1, score=0.241, total= 3.0min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1, score=0.249, total= 3.1min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5, score=0.255, total= 2.9min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5, score=0.258, total= 2.9min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5, score=0.249, total= 2.9min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5, score=0.252, total= 2.8min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5, score=0.262, total= 2.9min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.206, total=  32.1s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.216, total=  35.1s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.207, total=  32.2s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.221, total=  32.2s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.226, total=  31.1s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.221, total=  32.1s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.230, total=  33.4s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.225, total=  32.4s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.221, total=  32.3s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.237, total=  32.6s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.213, total=  31.9s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.219, total=  30.5s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.211, total=  31.3s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.215, total=  31.2s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.204, total=  31.0s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.228, total=  30.7s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.227, total=  31.2s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.224, total=  31.4s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.228, total=  30.3s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.228, total=  29.8s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.221, total=  55.2s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.234, total=  54.9s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.226, total=  56.4s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.235, total=  53.7s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.243, total=  56.3s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.242, total=  59.3s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.242, total=  56.8s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.239, total=  58.5s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.245, total=  55.2s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.255, total=  56.6s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.227, total=  51.7s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.241, total=  51.5s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.217, total=  53.2s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.230, total=  53.6s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.238, total=  54.0s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.237, total=  52.2s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.243, total=  53.1s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.229, total=  51.8s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.246, total=  50.6s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.261, total=  52.4s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1, score=0.229, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1, score=0.245, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1, score=0.241, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1, score=0.243, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=1, score=0.246, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5, score=0.252, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5, score=0.246, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5, score=0.248, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5, score=0.254, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=True, vect__min_df=5, score=0.260, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1, score=0.226, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1, score=0.237, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1, score=0.231, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1, score=0.237, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=1, score=0.239, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5, score=0.250, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5, score=0.256, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5, score=0.246, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5, score=0.250, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=50, tfidf__use_idf=False, vect__min_df=5, score=0.256, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1, score=0.234, total= 2.9min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1, score=0.245, total= 2.9min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1, score=0.234, total= 2.9min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1, score=0.241, total= 2.9min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=1, score=0.250, total= 3.0min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5, score=0.251, total= 3.0min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5, score=0.252, total= 3.0min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5, score=0.243, total= 2.9min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5, score=0.253, total= 2.8min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__min_df=5, score=0.266, total= 2.8min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1, score=0.226, total= 2.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1, score=0.243, total= 2.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1, score=0.233, total= 2.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1, score=0.237, total= 2.5min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=1, score=0.248, total= 2.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5, score=0.250, total= 2.5min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5, score=0.257, total= 2.5min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5, score=0.244, total= 2.5min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5, score=0.251, total= 2.6min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=100, tfidf__use_idf=False, vect__min_df=5, score=0.270, total= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed: 379.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(...\n",
       "                                                                                               oob_score=False,\n",
       "                                                                                               random_state=None,\n",
       "                                                                                               verbose=0,\n",
       "                                                                                               warm_start=False),\n",
       "                                                              n_jobs=None))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'clf__estimator__min_samples_split': [2, 5, 10],\n",
       "                         'clf__estimator__n_estimators': [10, 25, 50, 100],\n",
       "                         'tfidf__use_idf': [True, False],\n",
       "                         'vect__min_df': [1, 5]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__n_estimators': 100,\n",
       " 'tfidf__use_idf': True,\n",
       " 'vect__min_df': 5}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2567491761298042"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_preds_cv = model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.29      0.42      1569\n",
      "           1       0.81      0.97      0.88      4938\n",
      "\n",
      "    accuracy                           0.81      6507\n",
      "   macro avg       0.79      0.63      0.65      6507\n",
      "weighted avg       0.80      0.81      0.77      6507\n",
      "\n",
      "request\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      5403\n",
      "           1       0.87      0.46      0.60      1104\n",
      "\n",
      "    accuracy                           0.90      6507\n",
      "   macro avg       0.88      0.72      0.77      6507\n",
      "weighted avg       0.89      0.90      0.88      6507\n",
      "\n",
      "offer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6481\n",
      "           1       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           1.00      6507\n",
      "   macro avg       0.50      0.50      0.50      6507\n",
      "weighted avg       0.99      1.00      0.99      6507\n",
      "\n",
      "aid_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83      3793\n",
      "           1       0.80      0.65      0.71      2714\n",
      "\n",
      "    accuracy                           0.78      6507\n",
      "   macro avg       0.79      0.76      0.77      6507\n",
      "weighted avg       0.78      0.78      0.78      6507\n",
      "\n",
      "medical_help\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      5965\n",
      "           1       0.71      0.04      0.07       542\n",
      "\n",
      "    accuracy                           0.92      6507\n",
      "   macro avg       0.82      0.52      0.51      6507\n",
      "weighted avg       0.90      0.92      0.88      6507\n",
      "\n",
      "medical_products\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6160\n",
      "           1       0.89      0.07      0.13       347\n",
      "\n",
      "    accuracy                           0.95      6507\n",
      "   macro avg       0.92      0.53      0.55      6507\n",
      "weighted avg       0.95      0.95      0.93      6507\n",
      "\n",
      "search_and_rescue\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      6315\n",
      "           1       1.00      0.03      0.06       192\n",
      "\n",
      "    accuracy                           0.97      6507\n",
      "   macro avg       0.99      0.52      0.52      6507\n",
      "weighted avg       0.97      0.97      0.96      6507\n",
      "\n",
      "security"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6374\n",
      "           1       0.33      0.01      0.01       133\n",
      "\n",
      "    accuracy                           0.98      6507\n",
      "   macro avg       0.66      0.50      0.50      6507\n",
      "weighted avg       0.97      0.98      0.97      6507\n",
      "\n",
      "military\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6282\n",
      "           1       0.53      0.04      0.07       225\n",
      "\n",
      "    accuracy                           0.97      6507\n",
      "   macro avg       0.75      0.52      0.53      6507\n",
      "weighted avg       0.95      0.97      0.95      6507\n",
      "\n",
      "water\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6077\n",
      "           1       0.91      0.24      0.38       430\n",
      "\n",
      "    accuracy                           0.95      6507\n",
      "   macro avg       0.93      0.62      0.68      6507\n",
      "weighted avg       0.95      0.95      0.93      6507\n",
      "\n",
      "food\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      5776\n",
      "           1       0.86      0.41      0.56       731\n",
      "\n",
      "    accuracy                           0.93      6507\n",
      "   macro avg       0.89      0.70      0.76      6507\n",
      "weighted avg       0.92      0.93      0.91      6507\n",
      "\n",
      "shelter\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      5909\n",
      "           1       0.85      0.31      0.46       598\n",
      "\n",
      "    accuracy                           0.93      6507\n",
      "   macro avg       0.89      0.65      0.71      6507\n",
      "weighted avg       0.93      0.93      0.92      6507\n",
      "\n",
      "clothing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6406\n",
      "           1       0.83      0.10      0.18       101\n",
      "\n",
      "    accuracy                           0.99      6507\n",
      "   macro avg       0.91      0.55      0.58      6507\n",
      "weighted avg       0.98      0.99      0.98      6507\n",
      "\n",
      "money\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6339\n",
      "           1       0.78      0.04      0.08       168\n",
      "\n",
      "    accuracy                           0.97      6507\n",
      "   macro avg       0.88      0.52      0.53      6507\n",
      "weighted avg       0.97      0.97      0.96      6507\n",
      "\n",
      "missing_people\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6439\n",
      "           1       1.00      0.01      0.03        68\n",
      "\n",
      "    accuracy                           0.99      6507\n",
      "   macro avg       0.99      0.51      0.51      6507\n",
      "weighted avg       0.99      0.99      0.98      6507\n",
      "\n",
      "refugees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6299\n",
      "           1       0.33      0.01      0.02       208\n",
      "\n",
      "    accuracy                           0.97      6507\n",
      "   macro avg       0.65      0.50      0.50      6507\n",
      "weighted avg       0.95      0.97      0.95      6507\n",
      "\n",
      "death\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6213\n",
      "           1       0.83      0.12      0.21       294\n",
      "\n",
      "    accuracy                           0.96      6507\n",
      "   macro avg       0.90      0.56      0.59      6507\n",
      "weighted avg       0.95      0.96      0.94      6507\n",
      "\n",
      "other_aid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      5673\n",
      "           1       0.65      0.02      0.04       834\n",
      "\n",
      "    accuracy                           0.87      6507\n",
      "   macro avg       0.76      0.51      0.49      6507\n",
      "weighted avg       0.85      0.87      0.82      6507\n",
      "\n",
      "infrastructure_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      6088\n",
      "           1       0.00      0.00      0.00       419\n",
      "\n",
      "    accuracy                           0.94      6507\n",
      "   macro avg       0.47      0.50      0.48      6507\n",
      "weighted avg       0.88      0.94      0.90      6507\n",
      "\n",
      "transport\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6210\n",
      "           1       0.74      0.08      0.15       297\n",
      "\n",
      "    accuracy                           0.96      6507\n",
      "   macro avg       0.85      0.54      0.56      6507\n",
      "weighted avg       0.95      0.96      0.94      6507\n",
      "\n",
      "buildings\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6148\n",
      "           1       0.87      0.07      0.13       359\n",
      "\n",
      "    accuracy                           0.95      6507\n",
      "   macro avg       0.91      0.54      0.55      6507\n",
      "weighted avg       0.94      0.95      0.93      6507\n",
      "\n",
      "electricity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6380\n",
      "           1       0.88      0.06      0.10       127\n",
      "\n",
      "    accuracy                           0.98      6507\n",
      "   macro avg       0.93      0.53      0.55      6507\n",
      "weighted avg       0.98      0.98      0.97      6507\n",
      "\n",
      "tools\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6467\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.99      6507\n",
      "   macro avg       0.50      0.50      0.50      6507\n",
      "weighted avg       0.99      0.99      0.99      6507\n",
      "\n",
      "hospitals\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6436\n",
      "           1       0.00      0.00      0.00        71\n",
      "\n",
      "    accuracy                           0.99      6507\n",
      "   macro avg       0.49      0.50      0.50      6507\n",
      "weighted avg       0.98      0.99      0.98      6507\n",
      "\n",
      "shops\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6472\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.99      6507\n",
      "   macro avg       0.50      0.50      0.50      6507\n",
      "weighted avg       0.99      0.99      0.99      6507\n",
      "\n",
      "aid_centers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6435\n",
      "           1       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.99      6507\n",
      "   macro avg       0.49      0.50      0.50      6507\n",
      "weighted avg       0.98      0.99      0.98      6507\n",
      "\n",
      "other_infrastructure\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6226\n",
      "           1       0.00      0.00      0.00       281\n",
      "\n",
      "    accuracy                           0.96      6507\n",
      "   macro avg       0.48      0.50      0.49      6507\n",
      "weighted avg       0.92      0.96      0.94      6507\n",
      "\n",
      "weather_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      4693\n",
      "           1       0.86      0.67      0.75      1814\n",
      "\n",
      "    accuracy                           0.88      6507\n",
      "   macro avg       0.87      0.81      0.84      6507\n",
      "weighted avg       0.88      0.88      0.87      6507\n",
      "\n",
      "floods\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5973\n",
      "           1       0.92      0.48      0.63       534\n",
      "\n",
      "    accuracy                           0.95      6507\n",
      "   macro avg       0.94      0.74      0.80      6507\n",
      "weighted avg       0.95      0.95      0.95      6507\n",
      "\n",
      "storm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      5883\n",
      "           1       0.81      0.45      0.58       624\n",
      "\n",
      "    accuracy                           0.94      6507\n",
      "   macro avg       0.88      0.72      0.77      6507\n",
      "weighted avg       0.93      0.94      0.93      6507\n",
      "\n",
      "fire\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6435\n",
      "           1       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.99      6507\n",
      "   macro avg       0.49      0.50      0.50      6507\n",
      "weighted avg       0.98      0.99      0.98      6507\n",
      "\n",
      "earthquake\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      5901\n",
      "           1       0.89      0.76      0.82       606\n",
      "\n",
      "    accuracy                           0.97      6507\n",
      "   macro avg       0.93      0.87      0.90      6507\n",
      "weighted avg       0.97      0.97      0.97      6507\n",
      "\n",
      "cold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6367\n",
      "           1       1.00      0.04      0.08       140\n",
      "\n",
      "    accuracy                           0.98      6507\n",
      "   macro avg       0.99      0.52      0.54      6507\n",
      "weighted avg       0.98      0.98      0.97      6507\n",
      "\n",
      "other_weather\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6177\n",
      "           1       0.71      0.02      0.03       330\n",
      "\n",
      "    accuracy                           0.95      6507\n",
      "   macro avg       0.83      0.51      0.50      6507\n",
      "weighted avg       0.94      0.95      0.93      6507\n",
      "\n",
      "direct_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      5210\n",
      "           1       0.87      0.36      0.51      1297\n",
      "\n",
      "    accuracy                           0.86      6507\n",
      "   macro avg       0.87      0.67      0.71      6507\n",
      "weighted avg       0.86      0.86      0.84      6507\n",
      "\n",
      "count    9.000000\n",
      "mean     0.851604\n",
      "std      0.053219\n",
      "min      0.771124\n",
      "25%      0.817647\n",
      "50%      0.872271\n",
      "75%      0.883507\n",
      "max      0.917431\n",
      "Name: f1-score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cv_results = model_performance(Y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Try new model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#grid search\n",
    "\n",
    "parameters_2 = {'vect__min_df': [5, 10],\n",
    "              'tfidf__use_idf':[True],\n",
    "              'vect__binary':[True, False],\n",
    "              'clf__estimator__n_estimators':[100, 500, 1000], \n",
    "              'clf__estimator__min_samples_split':[1, 2]}\n",
    "\n",
    "model_cv_2 = GridSearchCV(estimator=model, param_grid=parameters_2, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline model 2\n",
    "def pipeline_model_2():\n",
    "    '''\n",
    "    build a pipeline model with the specificed transformers and estimator\n",
    "    '''\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf', TfidfTransformer())\n",
    "            ])),\n",
    "\n",
    "            #('starting_verb', StartingVerbExtractor()),\n",
    "            #(\"word_count\", WordCount()),\n",
    "            #(\"character_count\", CharacterCount()),\n",
    "            #(\"noun_count\", NounCount()),\n",
    "            #(\"verb_count\", VerbCount())\n",
    "        ])),\n",
    "\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])\n",
    "    #pipeline = Pipeline([('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    #                      ('tfidf', TfidfTransformer()),\n",
    "    #                      ('clf', MultiOutputClassifier(RandomForestClassifier()))])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9452633427737163"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuracy_model_2 = (y_preds_2 == Y_test).mean().mean()\n",
    "avg_accuracy_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = pipeline_model_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('features',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('text_pipeline',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('vect',\n",
       "                                                                  CountVectorizer(analyzer='word',\n",
       "                                                                                  binary=False,\n",
       "                                                                                  decode_error='strict',\n",
       "                                                                                  dtype=<class 'numpy.int64'>,\n",
       "                                                                                  encoding='utf-8',\n",
       "                                                                                  input='content',\n",
       "                                                                                  lowercase=True,\n",
       "                                                                                  max_df=1.0,\n",
       "                                                                                  max_features=None,\n",
       "                                                                                  min_df=1,\n",
       "                                                                                  ngram_range=(1,\n",
       "                                                                                               1),\n",
       "                                                                                  preprocessor=Non...\n",
       "                                                                        ccp_alpha=0.0,\n",
       "                                                                        class_weight=None,\n",
       "                                                                        criterion='gini',\n",
       "                                                                        max_depth=None,\n",
       "                                                                        max_features='auto',\n",
       "                                                                        max_leaf_nodes=None,\n",
       "                                                                        max_samples=None,\n",
       "                                                                        min_impurity_decrease=0.0,\n",
       "                                                                        min_impurity_split=None,\n",
       "                                                                        min_samples_leaf=1,\n",
       "                                                                        min_samples_split=2,\n",
       "                                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                                        n_estimators=100,\n",
       "                                                                        n_jobs=None,\n",
       "                                                                        oob_score=False,\n",
       "                                                                        random_state=None,\n",
       "                                                                        verbose=0,\n",
       "                                                                        warm_start=False),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#make predictions\n",
    "y_preds_2 = model_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "wavg_df_2 = create_report_summary(y_preds_2, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35.000000\n",
       "mean      0.931105\n",
       "std       0.058078\n",
       "min       0.768918\n",
       "25%       0.921070\n",
       "50%       0.942290\n",
       "75%       0.971146\n",
       "max       0.994010\n",
       "Name: f1-score, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'lowest quantile of f scores'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.794046</td>\n",
       "      <td>0.803903</td>\n",
       "      <td>0.768918</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.896604</td>\n",
       "      <td>0.897341</td>\n",
       "      <td>0.883021</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.783032</td>\n",
       "      <td>0.781927</td>\n",
       "      <td>0.777688</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.904734</td>\n",
       "      <td>0.919164</td>\n",
       "      <td>0.885168</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.929301</td>\n",
       "      <td>0.933303</td>\n",
       "      <td>0.919152</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.833315</td>\n",
       "      <td>0.872291</td>\n",
       "      <td>0.816404</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.875325</td>\n",
       "      <td>0.934993</td>\n",
       "      <td>0.904176</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.874433</td>\n",
       "      <td>0.875980</td>\n",
       "      <td>0.870815</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.860175</td>\n",
       "      <td>0.860612</td>\n",
       "      <td>0.836897</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision    recall  f1-score  support\n",
       "related                  0.794046  0.803903  0.768918   6507.0\n",
       "request                  0.896604  0.897341  0.883021   6507.0\n",
       "aid_related              0.783032  0.781927  0.777688   6507.0\n",
       "medical_help             0.904734  0.919164  0.885168   6507.0\n",
       "shelter                  0.929301  0.933303  0.919152   6507.0\n",
       "other_aid                0.833315  0.872291  0.816404   6507.0\n",
       "infrastructure_related   0.875325  0.934993  0.904176   6507.0\n",
       "weather_related          0.874433  0.875980  0.870815   6507.0\n",
       "direct_report            0.860175  0.860612  0.836897   6507.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'highest quantile of f scores'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.992025</td>\n",
       "      <td>0.996004</td>\n",
       "      <td>0.994010</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.982804</td>\n",
       "      <td>0.985400</td>\n",
       "      <td>0.979467</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.989809</td>\n",
       "      <td>0.989703</td>\n",
       "      <td>0.984731</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.981603</td>\n",
       "      <td>0.981251</td>\n",
       "      <td>0.972675</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.987743</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.990789</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.978296</td>\n",
       "      <td>0.989089</td>\n",
       "      <td>0.983663</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.989271</td>\n",
       "      <td>0.994621</td>\n",
       "      <td>0.991939</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.977992</td>\n",
       "      <td>0.988935</td>\n",
       "      <td>0.983433</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.977992</td>\n",
       "      <td>0.988935</td>\n",
       "      <td>0.983433</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                precision    recall  f1-score  support\n",
       "offer            0.992025  0.996004  0.994010   6507.0\n",
       "clothing         0.982804  0.985400  0.979467   6507.0\n",
       "missing_people   0.989809  0.989703  0.984731   6507.0\n",
       "electricity      0.981603  0.981251  0.972675   6507.0\n",
       "tools            0.987743  0.993853  0.990789   6507.0\n",
       "hospitals        0.978296  0.989089  0.983663   6507.0\n",
       "shops            0.989271  0.994621  0.991939   6507.0\n",
       "aid_centers      0.977992  0.988935  0.983433   6507.0\n",
       "fire             0.977992  0.988935  0.983433   6507.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weighted_avg_report(wavg_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv_2 = GridSearchCV(estimator=model, param_grid=parameters_2, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=nan, total=  12.2s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   24.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=nan, total=  12.7s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=nan, total=  13.0s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=nan, total=  12.2s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=nan, total=  12.8s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=nan, total=  12.6s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=nan, total=  12.4s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=nan, total=  12.3s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=nan, total=  12.4s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=nan, total=  12.8s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=nan, total=  12.3s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=nan, total=  12.5s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=nan, total=  13.3s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=nan, total=  12.9s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=nan, total=  12.4s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=nan, total=  13.3s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=nan, total=  13.4s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=nan, total=  12.7s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=nan, total=  12.7s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=nan, total=  13.0s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=nan, total=  13.1s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=nan, total=  13.4s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=nan, total=  13.4s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=nan, total=  13.2s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=nan, total=  12.8s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=nan, total=  12.6s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=nan, total=  12.7s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=nan, total=  12.6s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=nan, total=  12.6s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=nan, total=  13.1s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=nan, total=  13.2s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=nan, total=  12.6s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=nan, total=  12.8s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=nan, total=  12.6s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=nan, total=  12.7s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=nan, total=  12.6s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=nan, total=  12.4s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=nan, total=  12.5s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=nan, total=  12.5s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=nan, total=  13.4s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=nan, total=  12.8s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=nan, total=  12.9s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=nan, total=  12.9s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=nan, total=  13.1s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=nan, total=  13.0s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=nan, total=  12.7s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=nan, total=  13.2s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=nan, total=  13.2s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=nan, total=  13.1s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=nan, total=  12.7s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=nan, total=  12.8s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=nan, total=  12.7s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=nan, total=  12.8s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=nan, total=  12.8s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=nan, total=  13.0s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=nan, total=  12.7s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=nan, total=  13.4s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=nan, total=  12.6s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=nan, total=  12.6s\n",
      "[CV] clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=1, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=nan, total=  13.1s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=0.260, total= 3.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=0.257, total= 4.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=0.249, total= 4.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=0.256, total= 4.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=0.262, total= 4.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=0.252, total= 4.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=0.260, total= 4.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=0.253, total= 4.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=0.257, total= 4.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=0.274, total= 4.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=0.252, total= 4.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=0.256, total= 4.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=0.247, total= 4.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=0.256, total= 4.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=0.273, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=0.258, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=0.264, total= 4.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=0.249, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=0.254, total= 4.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=0.268, total= 4.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=0.255, total=19.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=0.259, total=19.6min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=0.247, total=19.6min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=0.260, total=19.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=0.268, total=19.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=0.257, total=18.9min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=0.261, total=19.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=0.256, total=19.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=0.261, total=18.9min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=0.272, total=19.6min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=0.258, total=26.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=0.262, total=30.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=0.255, total=32.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=0.257, total=30.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=0.272, total=31.7min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=0.257, total=26.9min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=0.264, total=21.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=0.249, total=24.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=0.263, total=31.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=500, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=0.272, total=29.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=0.262, total=66.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=0.258, total=59.9min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=0.254, total=47.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=0.258, total=45.4min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=5, score=0.269, total=46.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=0.255, total=45.0min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=0.263, total=45.9min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=0.252, total=45.7min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=0.264, total=41.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=True, vect__min_df=10, score=0.270, total=41.6min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=0.257, total=42.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=0.266, total=42.6min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=0.252, total=40.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=0.259, total=39.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=5, score=0.275, total=41.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=0.259, total=41.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=0.267, total=41.9min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=0.254, total=44.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=0.265, total=41.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=1000, tfidf__use_idf=True, vect__binary=False, vect__min_df=10, score=0.280, total=41.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed: 1480.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1d 1h 34min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(...\n",
       "                                                                                               random_state=None,\n",
       "                                                                                               verbose=0,\n",
       "                                                                                               warm_start=False),\n",
       "                                                              n_jobs=None))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'clf__estimator__min_samples_split': [1, 2],\n",
       "                         'clf__estimator__n_estimators': [100, 500, 1000],\n",
       "                         'tfidf__use_idf': [True],\n",
       "                         'vect__binary': [True, False],\n",
       "                         'vect__min_df': [5, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_cv_2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__n_estimators': 1000,\n",
       " 'tfidf__use_idf': True,\n",
       " 'vect__binary': False,\n",
       " 'vect__min_df': 10}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2649457268949014"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv_2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_preds_cv_2 = model_cv_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.30      0.43      1569\n",
      "           1       0.81      0.97      0.88      4938\n",
      "\n",
      "    accuracy                           0.81      6507\n",
      "   macro avg       0.78      0.64      0.66      6507\n",
      "weighted avg       0.80      0.81      0.77      6507\n",
      "\n",
      "request\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      5403\n",
      "           1       0.86      0.51      0.64      1104\n",
      "\n",
      "    accuracy                           0.90      6507\n",
      "   macro avg       0.89      0.75      0.79      6507\n",
      "weighted avg       0.90      0.90      0.89      6507\n",
      "\n",
      "offer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6481\n",
      "           1       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           1.00      6507\n",
      "   macro avg       0.50      0.50      0.50      6507\n",
      "weighted avg       0.99      1.00      0.99      6507\n",
      "\n",
      "aid_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82      3793\n",
      "           1       0.77      0.69      0.73      2714\n",
      "\n",
      "    accuracy                           0.79      6507\n",
      "   macro avg       0.78      0.77      0.77      6507\n",
      "weighted avg       0.78      0.79      0.78      6507\n",
      "\n",
      "medical_help\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      5965\n",
      "           1       0.67      0.09      0.17       542\n",
      "\n",
      "    accuracy                           0.92      6507\n",
      "   macro avg       0.80      0.54      0.56      6507\n",
      "weighted avg       0.90      0.92      0.89      6507\n",
      "\n",
      "medical_products\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      6160\n",
      "           1       0.88      0.15      0.26       347\n",
      "\n",
      "    accuracy                           0.95      6507\n",
      "   macro avg       0.92      0.57      0.62      6507\n",
      "weighted avg       0.95      0.95      0.94      6507\n",
      "\n",
      "search_and_rescue\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      6315\n",
      "           1       0.73      0.04      0.08       192\n",
      "\n",
      "    accuracy                           0.97      6507\n",
      "   macro avg       0.85      0.52      0.53      6507\n",
      "weighted avg       0.96      0.97      0.96      6507\n",
      "\n",
      "security\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6374\n",
      "           1       0.50      0.02      0.04       133\n",
      "\n",
      "    accuracy                           0.98      6507\n",
      "   macro avg       0.74      0.51      0.52      6507\n",
      "weighted avg       0.97      0.98      0.97      6507\n",
      "\n",
      "military\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6282\n",
      "           1       0.76      0.10      0.17       225\n",
      "\n",
      "    accuracy                           0.97      6507\n",
      "   macro avg       0.86      0.55      0.58      6507\n",
      "weighted avg       0.96      0.97      0.96      6507\n",
      "\n",
      "water\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6077\n",
      "           1       0.89      0.42      0.57       430\n",
      "\n",
      "    accuracy                           0.96      6507\n",
      "   macro avg       0.93      0.71      0.77      6507\n",
      "weighted avg       0.96      0.96      0.95      6507\n",
      "\n",
      "food\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      5776\n",
      "           1       0.82      0.71      0.76       731\n",
      "\n",
      "    accuracy                           0.95      6507\n",
      "   macro avg       0.89      0.85      0.87      6507\n",
      "weighted avg       0.95      0.95      0.95      6507\n",
      "\n",
      "shelter\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      5909\n",
      "           1       0.83      0.45      0.59       598\n",
      "\n",
      "    accuracy                           0.94      6507\n",
      "   macro avg       0.89      0.72      0.78      6507\n",
      "weighted avg       0.94      0.94      0.93      6507\n",
      "\n",
      "clothing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6406\n",
      "           1       0.82      0.14      0.24       101\n",
      "\n",
      "    accuracy                           0.99      6507\n",
      "   macro avg       0.91      0.57      0.62      6507\n",
      "weighted avg       0.98      0.99      0.98      6507\n",
      "\n",
      "money\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6339\n",
      "           1       0.82      0.05      0.10       168\n",
      "\n",
      "    accuracy                           0.98      6507\n",
      "   macro avg       0.90      0.53      0.54      6507\n",
      "weighted avg       0.97      0.98      0.96      6507\n",
      "\n",
      "missing_people\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6439\n",
      "           1       1.00      0.01      0.03        68\n",
      "\n",
      "    accuracy                           0.99      6507\n",
      "   macro avg       0.99      0.51      0.51      6507\n",
      "weighted avg       0.99      0.99      0.98      6507\n",
      "\n",
      "refugees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6299\n",
      "           1       0.67      0.05      0.09       208\n",
      "\n",
      "    accuracy                           0.97      6507\n",
      "   macro avg       0.82      0.52      0.54      6507\n",
      "weighted avg       0.96      0.97      0.96      6507\n",
      "\n",
      "death\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6213\n",
      "           1       0.88      0.24      0.38       294\n",
      "\n",
      "    accuracy                           0.96      6507\n",
      "   macro avg       0.92      0.62      0.68      6507\n",
      "weighted avg       0.96      0.96      0.95      6507\n",
      "\n",
      "other_aid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93      5673\n",
      "           1       0.68      0.04      0.07       834\n",
      "\n",
      "    accuracy                           0.87      6507\n",
      "   macro avg       0.78      0.52      0.50      6507\n",
      "weighted avg       0.85      0.87      0.82      6507\n",
      "\n",
      "infrastructure_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      6088\n",
      "           1       0.00      0.00      0.00       419\n",
      "\n",
      "    accuracy                           0.93      6507\n",
      "   macro avg       0.47      0.50      0.48      6507\n",
      "weighted avg       0.88      0.93      0.90      6507\n",
      "\n",
      "transport\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6210\n",
      "           1       0.73      0.11      0.19       297\n",
      "\n",
      "    accuracy                           0.96      6507\n",
      "   macro avg       0.85      0.55      0.59      6507\n",
      "weighted avg       0.95      0.96      0.94      6507\n",
      "\n",
      "buildings\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      6148\n",
      "           1       0.86      0.15      0.26       359\n",
      "\n",
      "    accuracy                           0.95      6507\n",
      "   macro avg       0.90      0.57      0.62      6507\n",
      "weighted avg       0.95      0.95      0.94      6507\n",
      "\n",
      "electricity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6380\n",
      "           1       0.78      0.06      0.10       127\n",
      "\n",
      "    accuracy                           0.98      6507\n",
      "   macro avg       0.88      0.53      0.55      6507\n",
      "weighted avg       0.98      0.98      0.97      6507\n",
      "\n",
      "tools\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6467\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.99      6507\n",
      "   macro avg       0.50      0.50      0.50      6507\n",
      "weighted avg       0.99      0.99      0.99      6507\n",
      "\n",
      "hospitals\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6436\n",
      "           1       0.00      0.00      0.00        71\n",
      "\n",
      "    accuracy                           0.99      6507\n",
      "   macro avg       0.49      0.50      0.50      6507\n",
      "weighted avg       0.98      0.99      0.98      6507\n",
      "\n",
      "shops\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6472\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.99      6507\n",
      "   macro avg       0.50      0.50      0.50      6507\n",
      "weighted avg       0.99      0.99      0.99      6507\n",
      "\n",
      "aid_centers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6435\n",
      "           1       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.99      6507\n",
      "   macro avg       0.49      0.50      0.50      6507\n",
      "weighted avg       0.98      0.99      0.98      6507\n",
      "\n",
      "other_infrastructure\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6226\n",
      "           1       0.00      0.00      0.00       281\n",
      "\n",
      "    accuracy                           0.96      6507\n",
      "   macro avg       0.48      0.50      0.49      6507\n",
      "weighted avg       0.92      0.96      0.94      6507\n",
      "\n",
      "weather_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92      4693\n",
      "           1       0.84      0.75      0.79      1814\n",
      "\n",
      "    accuracy                           0.89      6507\n",
      "   macro avg       0.87      0.85      0.86      6507\n",
      "weighted avg       0.89      0.89      0.89      6507\n",
      "\n",
      "floods\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5973\n",
      "           1       0.92      0.57      0.71       534\n",
      "\n",
      "    accuracy                           0.96      6507\n",
      "   macro avg       0.94      0.79      0.84      6507\n",
      "weighted avg       0.96      0.96      0.96      6507\n",
      "\n",
      "storm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      5883\n",
      "           1       0.78      0.64      0.70       624\n",
      "\n",
      "    accuracy                           0.95      6507\n",
      "   macro avg       0.87      0.81      0.84      6507\n",
      "weighted avg       0.94      0.95      0.95      6507\n",
      "\n",
      "fire\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6435\n",
      "           1       1.00      0.01      0.03        72\n",
      "\n",
      "    accuracy                           0.99      6507\n",
      "   macro avg       0.99      0.51      0.51      6507\n",
      "weighted avg       0.99      0.99      0.98      6507\n",
      "\n",
      "earthquake\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      5901\n",
      "           1       0.89      0.81      0.85       606\n",
      "\n",
      "    accuracy                           0.97      6507\n",
      "   macro avg       0.94      0.90      0.92      6507\n",
      "weighted avg       0.97      0.97      0.97      6507\n",
      "\n",
      "cold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6367\n",
      "           1       1.00      0.09      0.17       140\n",
      "\n",
      "    accuracy                           0.98      6507\n",
      "   macro avg       0.99      0.55      0.58      6507\n",
      "weighted avg       0.98      0.98      0.97      6507\n",
      "\n",
      "other_weather\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6177\n",
      "           1       0.77      0.03      0.06       330\n",
      "\n",
      "    accuracy                           0.95      6507\n",
      "   macro avg       0.86      0.51      0.52      6507\n",
      "weighted avg       0.94      0.95      0.93      6507\n",
      "\n",
      "direct_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92      5210\n",
      "           1       0.84      0.40      0.54      1297\n",
      "\n",
      "    accuracy                           0.86      6507\n",
      "   macro avg       0.85      0.69      0.73      6507\n",
      "weighted avg       0.86      0.86      0.84      6507\n",
      "\n",
      "count    9.000000\n",
      "mean     0.859255\n",
      "std      0.055942\n",
      "min      0.774758\n",
      "25%      0.821825\n",
      "50%      0.887077\n",
      "75%      0.892294\n",
      "max      0.933391\n",
      "Name: f1-score, dtype: float64\n",
      "Wall time: 5.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_2_results = model_performance(Y_test, y_preds_cv_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count    9.000000\n",
    "mean     0.859255\n",
    "std      0.055942\n",
    "min      0.774758\n",
    "25%      0.821825\n",
    "50%      0.887077\n",
    "75%      0.892294\n",
    "max      0.933391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline model 3\n",
    "def pipeline_model_3():\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf', TfidfTransformer())\n",
    "            ])),\n",
    "        ])),\n",
    "\n",
    "        ('clf', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = pipeline_model_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'features', 'clf', 'features__n_jobs', 'features__transformer_list', 'features__transformer_weights', 'features__verbose', 'features__text_pipeline', 'features__text_pipeline__memory', 'features__text_pipeline__steps', 'features__text_pipeline__verbose', 'features__text_pipeline__vect', 'features__text_pipeline__tfidf', 'features__text_pipeline__vect__analyzer', 'features__text_pipeline__vect__binary', 'features__text_pipeline__vect__decode_error', 'features__text_pipeline__vect__dtype', 'features__text_pipeline__vect__encoding', 'features__text_pipeline__vect__input', 'features__text_pipeline__vect__lowercase', 'features__text_pipeline__vect__max_df', 'features__text_pipeline__vect__max_features', 'features__text_pipeline__vect__min_df', 'features__text_pipeline__vect__ngram_range', 'features__text_pipeline__vect__preprocessor', 'features__text_pipeline__vect__stop_words', 'features__text_pipeline__vect__strip_accents', 'features__text_pipeline__vect__token_pattern', 'features__text_pipeline__vect__tokenizer', 'features__text_pipeline__vect__vocabulary', 'features__text_pipeline__tfidf__norm', 'features__text_pipeline__tfidf__smooth_idf', 'features__text_pipeline__tfidf__sublinear_tf', 'features__text_pipeline__tfidf__use_idf', 'clf__estimator__algorithm', 'clf__estimator__base_estimator', 'clf__estimator__learning_rate', 'clf__estimator__n_estimators', 'clf__estimator__random_state', 'clf__estimator', 'clf__n_jobs'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'features__vect__min_df': [1, 5],\n",
    "              'features__tfidf__use_idf':[True, False],\n",
    "          'clf__estimator__learning_rate':[0.01, 0.1, 0.5],\n",
    "          'clf__estimator__n_estimators':[100, 200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv_3 = GridSearchCV(estimator=model_3, \n",
    "                          scoring='f1_weighted', \n",
    "                          param_grid=parameters, \n",
    "                          verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "related                   19906\n",
       "request                    4474\n",
       "offer                       118\n",
       "aid_related               10860\n",
       "medical_help               2084\n",
       "medical_products           1313\n",
       "search_and_rescue           724\n",
       "security                    471\n",
       "military                    860\n",
       "water                      1672\n",
       "food                       2923\n",
       "shelter                    2314\n",
       "clothing                    405\n",
       "money                       604\n",
       "missing_people              298\n",
       "refugees                    875\n",
       "death                      1194\n",
       "other_aid                  3446\n",
       "infrastructure_related     1705\n",
       "transport                  1201\n",
       "buildings                  1333\n",
       "electricity                 532\n",
       "tools                       159\n",
       "hospitals                   283\n",
       "shops                       120\n",
       "aid_centers                 309\n",
       "other_infrastructure       1151\n",
       "weather_related            7297\n",
       "floods                     2155\n",
       "storm                      2443\n",
       "fire                        282\n",
       "earthquake                 2455\n",
       "cold                        530\n",
       "other_weather              1376\n",
       "direct_report              5075\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('features',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('text_pipeline',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('vect',\n",
       "                                                                  CountVectorizer(analyzer='word',\n",
       "                                                                                  binary=False,\n",
       "                                                                                  decode_error='strict',\n",
       "                                                                                  dtype=<class 'numpy.int64'>,\n",
       "                                                                                  encoding='utf-8',\n",
       "                                                                                  input='content',\n",
       "                                                                                  lowercase=True,\n",
       "                                                                                  max_df=1.0,\n",
       "                                                                                  max_features=None,\n",
       "                                                                                  min_df=1,\n",
       "                                                                                  ngram_range=(1,\n",
       "                                                                                               1),\n",
       "                                                                                  preprocessor=Non...\n",
       "                                                                                  tokenizer=<function tokenize at 0x00000250D2188EE8>,\n",
       "                                                                                  vocabulary=None)),\n",
       "                                                                 ('tfidf',\n",
       "                                                                  TfidfTransformer(norm='l2',\n",
       "                                                                                   smooth_idf=True,\n",
       "                                                                                   sublinear_tf=False,\n",
       "                                                                                   use_idf=True))],\n",
       "                                                          verbose=False))],\n",
       "                              transformer_weights=None, verbose=False)),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                                                    base_estimator=None,\n",
       "                                                                    learning_rate=1.0,\n",
       "                                                                    n_estimators=50,\n",
       "                                                                    random_state=42),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#make predictions\n",
    "y_preds_3 = model_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavg_df_3 = metrics_report(Y_test, y_preds_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.783542</td>\n",
       "      <td>0.801137</td>\n",
       "      <td>0.777111</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.889641</td>\n",
       "      <td>0.896419</td>\n",
       "      <td>0.889729</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.992023</td>\n",
       "      <td>0.995697</td>\n",
       "      <td>0.993857</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.758949</td>\n",
       "      <td>0.759029</td>\n",
       "      <td>0.754306</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.912669</td>\n",
       "      <td>0.926848</td>\n",
       "      <td>0.912353</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.949186</td>\n",
       "      <td>0.956508</td>\n",
       "      <td>0.950013</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.967028</td>\n",
       "      <td>0.973413</td>\n",
       "      <td>0.967423</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.967202</td>\n",
       "      <td>0.978638</td>\n",
       "      <td>0.970599</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.962603</td>\n",
       "      <td>0.968803</td>\n",
       "      <td>0.964185</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.961374</td>\n",
       "      <td>0.963578</td>\n",
       "      <td>0.962092</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.945052</td>\n",
       "      <td>0.947288</td>\n",
       "      <td>0.945744</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.939603</td>\n",
       "      <td>0.944368</td>\n",
       "      <td>0.939976</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.986114</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>0.986604</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.973065</td>\n",
       "      <td>0.977255</td>\n",
       "      <td>0.974218</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.986705</td>\n",
       "      <td>0.989857</td>\n",
       "      <td>0.987283</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.960310</td>\n",
       "      <td>0.968188</td>\n",
       "      <td>0.962677</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.965110</td>\n",
       "      <td>0.968803</td>\n",
       "      <td>0.965768</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.841107</td>\n",
       "      <td>0.872599</td>\n",
       "      <td>0.845232</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.931458</td>\n",
       "      <td>0.914852</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.949858</td>\n",
       "      <td>0.958967</td>\n",
       "      <td>0.950952</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.951246</td>\n",
       "      <td>0.957123</td>\n",
       "      <td>0.952565</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.978641</td>\n",
       "      <td>0.982634</td>\n",
       "      <td>0.979182</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.987737</td>\n",
       "      <td>0.992777</td>\n",
       "      <td>0.990250</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.981502</td>\n",
       "      <td>0.987245</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.991215</td>\n",
       "      <td>0.994467</td>\n",
       "      <td>0.992145</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.980675</td>\n",
       "      <td>0.986937</td>\n",
       "      <td>0.983381</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.935709</td>\n",
       "      <td>0.953588</td>\n",
       "      <td>0.941329</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.880764</td>\n",
       "      <td>0.881820</td>\n",
       "      <td>0.876986</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.956584</td>\n",
       "      <td>0.959275</td>\n",
       "      <td>0.956320</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.931598</td>\n",
       "      <td>0.937606</td>\n",
       "      <td>0.931841</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.986286</td>\n",
       "      <td>0.989242</td>\n",
       "      <td>0.987045</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.968326</td>\n",
       "      <td>0.969418</td>\n",
       "      <td>0.968479</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.979498</td>\n",
       "      <td>0.982634</td>\n",
       "      <td>0.979841</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.930208</td>\n",
       "      <td>0.947595</td>\n",
       "      <td>0.934688</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.855848</td>\n",
       "      <td>0.865222</td>\n",
       "      <td>0.854408</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision    recall  f1-score  support\n",
       "related                  0.783542  0.801137  0.777111   6507.0\n",
       "request                  0.889641  0.896419  0.889729   6507.0\n",
       "offer                    0.992023  0.995697  0.993857   6507.0\n",
       "aid_related              0.758949  0.759029  0.754306   6507.0\n",
       "medical_help             0.912669  0.926848  0.912353   6507.0\n",
       "medical_products         0.949186  0.956508  0.950013   6507.0\n",
       "search_and_rescue        0.967028  0.973413  0.967423   6507.0\n",
       "security                 0.967202  0.978638  0.970599   6507.0\n",
       "military                 0.962603  0.968803  0.964185   6507.0\n",
       "water                    0.961374  0.963578  0.962092   6507.0\n",
       "food                     0.945052  0.947288  0.945744   6507.0\n",
       "shelter                  0.939603  0.944368  0.939976   6507.0\n",
       "clothing                 0.986114  0.987859  0.986604   6507.0\n",
       "money                    0.973065  0.977255  0.974218   6507.0\n",
       "missing_people           0.986705  0.989857  0.987283   6507.0\n",
       "refugees                 0.960310  0.968188  0.962677   6507.0\n",
       "death                    0.965110  0.968803  0.965768   6507.0\n",
       "other_aid                0.841107  0.872599  0.845232   6507.0\n",
       "infrastructure_related   0.907995  0.931458  0.914852   6507.0\n",
       "transport                0.949858  0.958967  0.950952   6507.0\n",
       "buildings                0.951246  0.957123  0.952565   6507.0\n",
       "electricity              0.978641  0.982634  0.979182   6507.0\n",
       "tools                    0.987737  0.992777  0.990250   6507.0\n",
       "hospitals                0.981502  0.987245  0.983908   6507.0\n",
       "shops                    0.991215  0.994467  0.992145   6507.0\n",
       "aid_centers              0.980675  0.986937  0.983381   6507.0\n",
       "other_infrastructure     0.935709  0.953588  0.941329   6507.0\n",
       "weather_related          0.880764  0.881820  0.876986   6507.0\n",
       "floods                   0.956584  0.959275  0.956320   6507.0\n",
       "storm                    0.931598  0.937606  0.931841   6507.0\n",
       "fire                     0.986286  0.989242  0.987045   6507.0\n",
       "earthquake               0.968326  0.969418  0.968479   6507.0\n",
       "cold                     0.979498  0.982634  0.979841   6507.0\n",
       "other_weather            0.930208  0.947595  0.934688   6507.0\n",
       "direct_report            0.855848  0.865222  0.854408   6507.0"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavg_df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35.000000\n",
       "mean      0.940781\n",
       "std       0.057800\n",
       "min       0.754306\n",
       "25%       0.933265\n",
       "50%       0.962092\n",
       "75%       0.979511\n",
       "max       0.993857\n",
       "Name: f1-score, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'lowest quantile of f scores'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.783542</td>\n",
       "      <td>0.801137</td>\n",
       "      <td>0.777111</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.889641</td>\n",
       "      <td>0.896419</td>\n",
       "      <td>0.889729</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.758949</td>\n",
       "      <td>0.759029</td>\n",
       "      <td>0.754306</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.912669</td>\n",
       "      <td>0.926848</td>\n",
       "      <td>0.912353</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.841107</td>\n",
       "      <td>0.872599</td>\n",
       "      <td>0.845232</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.931458</td>\n",
       "      <td>0.914852</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.880764</td>\n",
       "      <td>0.881820</td>\n",
       "      <td>0.876986</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.931598</td>\n",
       "      <td>0.937606</td>\n",
       "      <td>0.931841</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.855848</td>\n",
       "      <td>0.865222</td>\n",
       "      <td>0.854408</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision    recall  f1-score  support\n",
       "related                  0.783542  0.801137  0.777111   6507.0\n",
       "request                  0.889641  0.896419  0.889729   6507.0\n",
       "aid_related              0.758949  0.759029  0.754306   6507.0\n",
       "medical_help             0.912669  0.926848  0.912353   6507.0\n",
       "other_aid                0.841107  0.872599  0.845232   6507.0\n",
       "infrastructure_related   0.907995  0.931458  0.914852   6507.0\n",
       "weather_related          0.880764  0.881820  0.876986   6507.0\n",
       "storm                    0.931598  0.937606  0.931841   6507.0\n",
       "direct_report            0.855848  0.865222  0.854408   6507.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'highest quantile of f scores'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.992023</td>\n",
       "      <td>0.995697</td>\n",
       "      <td>0.993857</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.986114</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>0.986604</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.986705</td>\n",
       "      <td>0.989857</td>\n",
       "      <td>0.987283</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.987737</td>\n",
       "      <td>0.992777</td>\n",
       "      <td>0.990250</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.981502</td>\n",
       "      <td>0.987245</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.991215</td>\n",
       "      <td>0.994467</td>\n",
       "      <td>0.992145</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.980675</td>\n",
       "      <td>0.986937</td>\n",
       "      <td>0.983381</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.986286</td>\n",
       "      <td>0.989242</td>\n",
       "      <td>0.987045</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.979498</td>\n",
       "      <td>0.982634</td>\n",
       "      <td>0.979841</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                precision    recall  f1-score  support\n",
       "offer            0.992023  0.995697  0.993857   6507.0\n",
       "clothing         0.986114  0.987859  0.986604   6507.0\n",
       "missing_people   0.986705  0.989857  0.987283   6507.0\n",
       "tools            0.987737  0.992777  0.990250   6507.0\n",
       "hospitals        0.981502  0.987245  0.983908   6507.0\n",
       "shops            0.991215  0.994467  0.992145   6507.0\n",
       "aid_centers      0.980675  0.986937  0.983381   6507.0\n",
       "fire             0.986286  0.989242  0.987045   6507.0\n",
       "cold             0.979498  0.982634  0.979841   6507.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weighted_avg_report(wavg_df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.783542</td>\n",
       "      <td>0.801137</td>\n",
       "      <td>0.777111</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.889641</td>\n",
       "      <td>0.896419</td>\n",
       "      <td>0.889729</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.992023</td>\n",
       "      <td>0.995697</td>\n",
       "      <td>0.993857</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.758949</td>\n",
       "      <td>0.759029</td>\n",
       "      <td>0.754306</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.912669</td>\n",
       "      <td>0.926848</td>\n",
       "      <td>0.912353</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.949186</td>\n",
       "      <td>0.956508</td>\n",
       "      <td>0.950013</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.967028</td>\n",
       "      <td>0.973413</td>\n",
       "      <td>0.967423</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.967202</td>\n",
       "      <td>0.978638</td>\n",
       "      <td>0.970599</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.962603</td>\n",
       "      <td>0.968803</td>\n",
       "      <td>0.964185</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.961374</td>\n",
       "      <td>0.963578</td>\n",
       "      <td>0.962092</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.945052</td>\n",
       "      <td>0.947288</td>\n",
       "      <td>0.945744</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.939603</td>\n",
       "      <td>0.944368</td>\n",
       "      <td>0.939976</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.986114</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>0.986604</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.973065</td>\n",
       "      <td>0.977255</td>\n",
       "      <td>0.974218</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.986705</td>\n",
       "      <td>0.989857</td>\n",
       "      <td>0.987283</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.960310</td>\n",
       "      <td>0.968188</td>\n",
       "      <td>0.962677</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.965110</td>\n",
       "      <td>0.968803</td>\n",
       "      <td>0.965768</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.841107</td>\n",
       "      <td>0.872599</td>\n",
       "      <td>0.845232</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.931458</td>\n",
       "      <td>0.914852</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.949858</td>\n",
       "      <td>0.958967</td>\n",
       "      <td>0.950952</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.951246</td>\n",
       "      <td>0.957123</td>\n",
       "      <td>0.952565</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.978641</td>\n",
       "      <td>0.982634</td>\n",
       "      <td>0.979182</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.987737</td>\n",
       "      <td>0.992777</td>\n",
       "      <td>0.990250</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.981502</td>\n",
       "      <td>0.987245</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.991215</td>\n",
       "      <td>0.994467</td>\n",
       "      <td>0.992145</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.980675</td>\n",
       "      <td>0.986937</td>\n",
       "      <td>0.983381</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.935709</td>\n",
       "      <td>0.953588</td>\n",
       "      <td>0.941329</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.880764</td>\n",
       "      <td>0.881820</td>\n",
       "      <td>0.876986</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.956584</td>\n",
       "      <td>0.959275</td>\n",
       "      <td>0.956320</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.931598</td>\n",
       "      <td>0.937606</td>\n",
       "      <td>0.931841</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.986286</td>\n",
       "      <td>0.989242</td>\n",
       "      <td>0.987045</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.968326</td>\n",
       "      <td>0.969418</td>\n",
       "      <td>0.968479</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.979498</td>\n",
       "      <td>0.982634</td>\n",
       "      <td>0.979841</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.930208</td>\n",
       "      <td>0.947595</td>\n",
       "      <td>0.934688</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.855848</td>\n",
       "      <td>0.865222</td>\n",
       "      <td>0.854408</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision    recall  f1-score  support\n",
       "related                  0.783542  0.801137  0.777111   6507.0\n",
       "request                  0.889641  0.896419  0.889729   6507.0\n",
       "offer                    0.992023  0.995697  0.993857   6507.0\n",
       "aid_related              0.758949  0.759029  0.754306   6507.0\n",
       "medical_help             0.912669  0.926848  0.912353   6507.0\n",
       "medical_products         0.949186  0.956508  0.950013   6507.0\n",
       "search_and_rescue        0.967028  0.973413  0.967423   6507.0\n",
       "security                 0.967202  0.978638  0.970599   6507.0\n",
       "military                 0.962603  0.968803  0.964185   6507.0\n",
       "water                    0.961374  0.963578  0.962092   6507.0\n",
       "food                     0.945052  0.947288  0.945744   6507.0\n",
       "shelter                  0.939603  0.944368  0.939976   6507.0\n",
       "clothing                 0.986114  0.987859  0.986604   6507.0\n",
       "money                    0.973065  0.977255  0.974218   6507.0\n",
       "missing_people           0.986705  0.989857  0.987283   6507.0\n",
       "refugees                 0.960310  0.968188  0.962677   6507.0\n",
       "death                    0.965110  0.968803  0.965768   6507.0\n",
       "other_aid                0.841107  0.872599  0.845232   6507.0\n",
       "infrastructure_related   0.907995  0.931458  0.914852   6507.0\n",
       "transport                0.949858  0.958967  0.950952   6507.0\n",
       "buildings                0.951246  0.957123  0.952565   6507.0\n",
       "electricity              0.978641  0.982634  0.979182   6507.0\n",
       "tools                    0.987737  0.992777  0.990250   6507.0\n",
       "hospitals                0.981502  0.987245  0.983908   6507.0\n",
       "shops                    0.991215  0.994467  0.992145   6507.0\n",
       "aid_centers              0.980675  0.986937  0.983381   6507.0\n",
       "other_infrastructure     0.935709  0.953588  0.941329   6507.0\n",
       "weather_related          0.880764  0.881820  0.876986   6507.0\n",
       "floods                   0.956584  0.959275  0.956320   6507.0\n",
       "storm                    0.931598  0.937606  0.931841   6507.0\n",
       "fire                     0.986286  0.989242  0.987045   6507.0\n",
       "earthquake               0.968326  0.969418  0.968479   6507.0\n",
       "cold                     0.979498  0.982634  0.979841   6507.0\n",
       "other_weather            0.930208  0.947595  0.934688   6507.0\n",
       "direct_report            0.855848  0.865222  0.854408   6507.0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_report(Y_test, y_preds_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Model 3 Run again, Tokenize has no stemming\n",
    "\n",
    "End result mean of f-score is 0.94, slightly less than when stemming is present. Therefore decided to keep stemming in the tokenize function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#make predictions\n",
    "y_preds_3 = model_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavg_df_3 = metrics_report(Y_test, y_preds_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.783542</td>\n",
       "      <td>0.801137</td>\n",
       "      <td>0.777111</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.889641</td>\n",
       "      <td>0.896419</td>\n",
       "      <td>0.889729</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.992023</td>\n",
       "      <td>0.995697</td>\n",
       "      <td>0.993857</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.758949</td>\n",
       "      <td>0.759029</td>\n",
       "      <td>0.754306</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.912669</td>\n",
       "      <td>0.926848</td>\n",
       "      <td>0.912353</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.949186</td>\n",
       "      <td>0.956508</td>\n",
       "      <td>0.950013</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.967028</td>\n",
       "      <td>0.973413</td>\n",
       "      <td>0.967423</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.967202</td>\n",
       "      <td>0.978638</td>\n",
       "      <td>0.970599</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.962603</td>\n",
       "      <td>0.968803</td>\n",
       "      <td>0.964185</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.961374</td>\n",
       "      <td>0.963578</td>\n",
       "      <td>0.962092</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.945052</td>\n",
       "      <td>0.947288</td>\n",
       "      <td>0.945744</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.939603</td>\n",
       "      <td>0.944368</td>\n",
       "      <td>0.939976</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.986114</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>0.986604</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.973065</td>\n",
       "      <td>0.977255</td>\n",
       "      <td>0.974218</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.986705</td>\n",
       "      <td>0.989857</td>\n",
       "      <td>0.987283</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.960310</td>\n",
       "      <td>0.968188</td>\n",
       "      <td>0.962677</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.965110</td>\n",
       "      <td>0.968803</td>\n",
       "      <td>0.965768</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.841107</td>\n",
       "      <td>0.872599</td>\n",
       "      <td>0.845232</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.931458</td>\n",
       "      <td>0.914852</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.949858</td>\n",
       "      <td>0.958967</td>\n",
       "      <td>0.950952</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.951246</td>\n",
       "      <td>0.957123</td>\n",
       "      <td>0.952565</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.978641</td>\n",
       "      <td>0.982634</td>\n",
       "      <td>0.979182</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.987737</td>\n",
       "      <td>0.992777</td>\n",
       "      <td>0.990250</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.981502</td>\n",
       "      <td>0.987245</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.991215</td>\n",
       "      <td>0.994467</td>\n",
       "      <td>0.992145</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.980675</td>\n",
       "      <td>0.986937</td>\n",
       "      <td>0.983381</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.935709</td>\n",
       "      <td>0.953588</td>\n",
       "      <td>0.941329</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.880764</td>\n",
       "      <td>0.881820</td>\n",
       "      <td>0.876986</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.956584</td>\n",
       "      <td>0.959275</td>\n",
       "      <td>0.956320</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.931598</td>\n",
       "      <td>0.937606</td>\n",
       "      <td>0.931841</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.986286</td>\n",
       "      <td>0.989242</td>\n",
       "      <td>0.987045</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.968326</td>\n",
       "      <td>0.969418</td>\n",
       "      <td>0.968479</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.979498</td>\n",
       "      <td>0.982634</td>\n",
       "      <td>0.979841</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.930208</td>\n",
       "      <td>0.947595</td>\n",
       "      <td>0.934688</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.855848</td>\n",
       "      <td>0.865222</td>\n",
       "      <td>0.854408</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision    recall  f1-score  support\n",
       "related                  0.783542  0.801137  0.777111   6507.0\n",
       "request                  0.889641  0.896419  0.889729   6507.0\n",
       "offer                    0.992023  0.995697  0.993857   6507.0\n",
       "aid_related              0.758949  0.759029  0.754306   6507.0\n",
       "medical_help             0.912669  0.926848  0.912353   6507.0\n",
       "medical_products         0.949186  0.956508  0.950013   6507.0\n",
       "search_and_rescue        0.967028  0.973413  0.967423   6507.0\n",
       "security                 0.967202  0.978638  0.970599   6507.0\n",
       "military                 0.962603  0.968803  0.964185   6507.0\n",
       "water                    0.961374  0.963578  0.962092   6507.0\n",
       "food                     0.945052  0.947288  0.945744   6507.0\n",
       "shelter                  0.939603  0.944368  0.939976   6507.0\n",
       "clothing                 0.986114  0.987859  0.986604   6507.0\n",
       "money                    0.973065  0.977255  0.974218   6507.0\n",
       "missing_people           0.986705  0.989857  0.987283   6507.0\n",
       "refugees                 0.960310  0.968188  0.962677   6507.0\n",
       "death                    0.965110  0.968803  0.965768   6507.0\n",
       "other_aid                0.841107  0.872599  0.845232   6507.0\n",
       "infrastructure_related   0.907995  0.931458  0.914852   6507.0\n",
       "transport                0.949858  0.958967  0.950952   6507.0\n",
       "buildings                0.951246  0.957123  0.952565   6507.0\n",
       "electricity              0.978641  0.982634  0.979182   6507.0\n",
       "tools                    0.987737  0.992777  0.990250   6507.0\n",
       "hospitals                0.981502  0.987245  0.983908   6507.0\n",
       "shops                    0.991215  0.994467  0.992145   6507.0\n",
       "aid_centers              0.980675  0.986937  0.983381   6507.0\n",
       "other_infrastructure     0.935709  0.953588  0.941329   6507.0\n",
       "weather_related          0.880764  0.881820  0.876986   6507.0\n",
       "floods                   0.956584  0.959275  0.956320   6507.0\n",
       "storm                    0.931598  0.937606  0.931841   6507.0\n",
       "fire                     0.986286  0.989242  0.987045   6507.0\n",
       "earthquake               0.968326  0.969418  0.968479   6507.0\n",
       "cold                     0.979498  0.982634  0.979841   6507.0\n",
       "other_weather            0.930208  0.947595  0.934688   6507.0\n",
       "direct_report            0.855848  0.865222  0.854408   6507.0"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavg_df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35.000000\n",
       "mean      0.940781\n",
       "std       0.057800\n",
       "min       0.754306\n",
       "25%       0.933265\n",
       "50%       0.962092\n",
       "75%       0.979511\n",
       "max       0.993857\n",
       "Name: f1-score, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'lowest quantile of f scores'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.783542</td>\n",
       "      <td>0.801137</td>\n",
       "      <td>0.777111</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.889641</td>\n",
       "      <td>0.896419</td>\n",
       "      <td>0.889729</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.758949</td>\n",
       "      <td>0.759029</td>\n",
       "      <td>0.754306</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.912669</td>\n",
       "      <td>0.926848</td>\n",
       "      <td>0.912353</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.841107</td>\n",
       "      <td>0.872599</td>\n",
       "      <td>0.845232</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.931458</td>\n",
       "      <td>0.914852</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.880764</td>\n",
       "      <td>0.881820</td>\n",
       "      <td>0.876986</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.931598</td>\n",
       "      <td>0.937606</td>\n",
       "      <td>0.931841</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.855848</td>\n",
       "      <td>0.865222</td>\n",
       "      <td>0.854408</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision    recall  f1-score  support\n",
       "related                  0.783542  0.801137  0.777111   6507.0\n",
       "request                  0.889641  0.896419  0.889729   6507.0\n",
       "aid_related              0.758949  0.759029  0.754306   6507.0\n",
       "medical_help             0.912669  0.926848  0.912353   6507.0\n",
       "other_aid                0.841107  0.872599  0.845232   6507.0\n",
       "infrastructure_related   0.907995  0.931458  0.914852   6507.0\n",
       "weather_related          0.880764  0.881820  0.876986   6507.0\n",
       "storm                    0.931598  0.937606  0.931841   6507.0\n",
       "direct_report            0.855848  0.865222  0.854408   6507.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'highest quantile of f scores'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.992023</td>\n",
       "      <td>0.995697</td>\n",
       "      <td>0.993857</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.986114</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>0.986604</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.986705</td>\n",
       "      <td>0.989857</td>\n",
       "      <td>0.987283</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.987737</td>\n",
       "      <td>0.992777</td>\n",
       "      <td>0.990250</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.981502</td>\n",
       "      <td>0.987245</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.991215</td>\n",
       "      <td>0.994467</td>\n",
       "      <td>0.992145</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.980675</td>\n",
       "      <td>0.986937</td>\n",
       "      <td>0.983381</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.986286</td>\n",
       "      <td>0.989242</td>\n",
       "      <td>0.987045</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.979498</td>\n",
       "      <td>0.982634</td>\n",
       "      <td>0.979841</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                precision    recall  f1-score  support\n",
       "offer            0.992023  0.995697  0.993857   6507.0\n",
       "clothing         0.986114  0.987859  0.986604   6507.0\n",
       "missing_people   0.986705  0.989857  0.987283   6507.0\n",
       "tools            0.987737  0.992777  0.990250   6507.0\n",
       "hospitals        0.981502  0.987245  0.983908   6507.0\n",
       "shops            0.991215  0.994467  0.992145   6507.0\n",
       "aid_centers      0.980675  0.986937  0.983381   6507.0\n",
       "fire             0.986286  0.989242  0.987045   6507.0\n",
       "cold             0.979498  0.982634  0.979841   6507.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weighted_avg_report(wavg_df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.783542</td>\n",
       "      <td>0.801137</td>\n",
       "      <td>0.777111</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.889641</td>\n",
       "      <td>0.896419</td>\n",
       "      <td>0.889729</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.992023</td>\n",
       "      <td>0.995697</td>\n",
       "      <td>0.993857</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.758949</td>\n",
       "      <td>0.759029</td>\n",
       "      <td>0.754306</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.912669</td>\n",
       "      <td>0.926848</td>\n",
       "      <td>0.912353</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.949186</td>\n",
       "      <td>0.956508</td>\n",
       "      <td>0.950013</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.967028</td>\n",
       "      <td>0.973413</td>\n",
       "      <td>0.967423</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.967202</td>\n",
       "      <td>0.978638</td>\n",
       "      <td>0.970599</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.962603</td>\n",
       "      <td>0.968803</td>\n",
       "      <td>0.964185</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.961374</td>\n",
       "      <td>0.963578</td>\n",
       "      <td>0.962092</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.945052</td>\n",
       "      <td>0.947288</td>\n",
       "      <td>0.945744</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.939603</td>\n",
       "      <td>0.944368</td>\n",
       "      <td>0.939976</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.986114</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>0.986604</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.973065</td>\n",
       "      <td>0.977255</td>\n",
       "      <td>0.974218</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.986705</td>\n",
       "      <td>0.989857</td>\n",
       "      <td>0.987283</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.960310</td>\n",
       "      <td>0.968188</td>\n",
       "      <td>0.962677</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.965110</td>\n",
       "      <td>0.968803</td>\n",
       "      <td>0.965768</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.841107</td>\n",
       "      <td>0.872599</td>\n",
       "      <td>0.845232</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.931458</td>\n",
       "      <td>0.914852</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.949858</td>\n",
       "      <td>0.958967</td>\n",
       "      <td>0.950952</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.951246</td>\n",
       "      <td>0.957123</td>\n",
       "      <td>0.952565</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.978641</td>\n",
       "      <td>0.982634</td>\n",
       "      <td>0.979182</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.987737</td>\n",
       "      <td>0.992777</td>\n",
       "      <td>0.990250</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.981502</td>\n",
       "      <td>0.987245</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.991215</td>\n",
       "      <td>0.994467</td>\n",
       "      <td>0.992145</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.980675</td>\n",
       "      <td>0.986937</td>\n",
       "      <td>0.983381</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.935709</td>\n",
       "      <td>0.953588</td>\n",
       "      <td>0.941329</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.880764</td>\n",
       "      <td>0.881820</td>\n",
       "      <td>0.876986</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.956584</td>\n",
       "      <td>0.959275</td>\n",
       "      <td>0.956320</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.931598</td>\n",
       "      <td>0.937606</td>\n",
       "      <td>0.931841</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.986286</td>\n",
       "      <td>0.989242</td>\n",
       "      <td>0.987045</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.968326</td>\n",
       "      <td>0.969418</td>\n",
       "      <td>0.968479</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.979498</td>\n",
       "      <td>0.982634</td>\n",
       "      <td>0.979841</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.930208</td>\n",
       "      <td>0.947595</td>\n",
       "      <td>0.934688</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.855848</td>\n",
       "      <td>0.865222</td>\n",
       "      <td>0.854408</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision    recall  f1-score  support\n",
       "related                  0.783542  0.801137  0.777111   6507.0\n",
       "request                  0.889641  0.896419  0.889729   6507.0\n",
       "offer                    0.992023  0.995697  0.993857   6507.0\n",
       "aid_related              0.758949  0.759029  0.754306   6507.0\n",
       "medical_help             0.912669  0.926848  0.912353   6507.0\n",
       "medical_products         0.949186  0.956508  0.950013   6507.0\n",
       "search_and_rescue        0.967028  0.973413  0.967423   6507.0\n",
       "security                 0.967202  0.978638  0.970599   6507.0\n",
       "military                 0.962603  0.968803  0.964185   6507.0\n",
       "water                    0.961374  0.963578  0.962092   6507.0\n",
       "food                     0.945052  0.947288  0.945744   6507.0\n",
       "shelter                  0.939603  0.944368  0.939976   6507.0\n",
       "clothing                 0.986114  0.987859  0.986604   6507.0\n",
       "money                    0.973065  0.977255  0.974218   6507.0\n",
       "missing_people           0.986705  0.989857  0.987283   6507.0\n",
       "refugees                 0.960310  0.968188  0.962677   6507.0\n",
       "death                    0.965110  0.968803  0.965768   6507.0\n",
       "other_aid                0.841107  0.872599  0.845232   6507.0\n",
       "infrastructure_related   0.907995  0.931458  0.914852   6507.0\n",
       "transport                0.949858  0.958967  0.950952   6507.0\n",
       "buildings                0.951246  0.957123  0.952565   6507.0\n",
       "electricity              0.978641  0.982634  0.979182   6507.0\n",
       "tools                    0.987737  0.992777  0.990250   6507.0\n",
       "hospitals                0.981502  0.987245  0.983908   6507.0\n",
       "shops                    0.991215  0.994467  0.992145   6507.0\n",
       "aid_centers              0.980675  0.986937  0.983381   6507.0\n",
       "other_infrastructure     0.935709  0.953588  0.941329   6507.0\n",
       "weather_related          0.880764  0.881820  0.876986   6507.0\n",
       "floods                   0.956584  0.959275  0.956320   6507.0\n",
       "storm                    0.931598  0.937606  0.931841   6507.0\n",
       "fire                     0.986286  0.989242  0.987045   6507.0\n",
       "earthquake               0.968326  0.969418  0.968479   6507.0\n",
       "cold                     0.979498  0.982634  0.979841   6507.0\n",
       "other_weather            0.930208  0.947595  0.934688   6507.0\n",
       "direct_report            0.855848  0.865222  0.854408   6507.0"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_report(Y_test, y_preds_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix as confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_mat(Y_test, y_preds):\n",
    "    '''\n",
    "    prints a confusion matrix of each var in each label\n",
    "    '''\n",
    "    #accuracy_df = pd.DataFrame(columns=['Accuracy score'])\n",
    "    actual = np.array(Y_test)\n",
    "    col_names = list(Y_test.columns.values)\n",
    "    for i in range(len(Y_test.columns)):\n",
    "        key = col_names[i]\n",
    "        confusion_mat = confusion_matrix(actual[:,i], y_preds[:,i])\n",
    "        print(key, confusion_mat)\n",
    "    #for pred, actual, col in zip(y_preds.transpose(), Y_test.values.transpose(), Y_test.columns):\n",
    "        #results_dict[col] = accuracy_score(np.(Y_test[col]), y_preds[col])\n",
    "    #return accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related [[[4664  274]\n",
      "  [1020  549]]\n",
      "\n",
      " [[ 549 1020]\n",
      "  [ 274 4664]]]\n",
      "request [[[ 618  486]\n",
      "  [ 188 5215]]\n",
      "\n",
      " [[5215  188]\n",
      "  [ 486  618]]]\n",
      "offer [[[   0   26]\n",
      "  [   2 6479]]\n",
      "\n",
      " [[6479    2]\n",
      "  [  26    0]]]\n",
      "aid_related [[[1682 1032]\n",
      "  [ 536 3257]]\n",
      "\n",
      " [[3257  536]\n",
      "  [1032 1682]]]\n",
      "medical_help [[[ 143  399]\n",
      "  [  77 5888]]\n",
      "\n",
      " [[5888   77]\n",
      "  [ 399  143]]]\n",
      "medical_products [[[ 123  224]\n",
      "  [  59 6101]]\n",
      "\n",
      " [[6101   59]\n",
      "  [ 224  123]]]\n",
      "search_and_rescue [[[  45  147]\n",
      "  [  26 6289]]\n",
      "\n",
      " [[6289   26]\n",
      "  [ 147   45]]]\n",
      "security [[[   6  127]\n",
      "  [  12 6362]]\n",
      "\n",
      " [[6362   12]\n",
      "  [ 127    6]]]\n",
      "military [[[  71  154]\n",
      "  [  49 6233]]\n",
      "\n",
      " [[6233   49]\n",
      "  [ 154   71]]]\n",
      "water [[[ 277  153]\n",
      "  [  84 5993]]\n",
      "\n",
      " [[5993   84]\n",
      "  [ 153  277]]]\n",
      "food [[[ 514  217]\n",
      "  [ 126 5650]]\n",
      "\n",
      " [[5650  126]\n",
      "  [ 217  514]]]\n",
      "shelter [[[ 329  269]\n",
      "  [  93 5816]]\n",
      "\n",
      " [[5816   93]\n",
      "  [ 269  329]]]\n",
      "clothing [[[  44   57]\n",
      "  [  22 6384]]\n",
      "\n",
      " [[6384   22]\n",
      "  [  57   44]]]\n",
      "money [[[  58  110]\n",
      "  [  38 6301]]\n",
      "\n",
      " [[6301   38]\n",
      "  [ 110   58]]]\n",
      "missing_people [[[  12   56]\n",
      "  [  10 6429]]\n",
      "\n",
      " [[6429   10]\n",
      "  [  56   12]]]\n",
      "refugees [[[  50  158]\n",
      "  [  49 6250]]\n",
      "\n",
      " [[6250   49]\n",
      "  [ 158   50]]]\n",
      "death [[[ 143  151]\n",
      "  [  52 6161]]\n",
      "\n",
      " [[6161   52]\n",
      "  [ 151  143]]]\n",
      "other_aid [[[ 151  683]\n",
      "  [ 146 5527]]\n",
      "\n",
      " [[5527  146]\n",
      "  [ 683  151]]]\n",
      "infrastructure_related [[[  55  364]\n",
      "  [  82 6006]]\n",
      "\n",
      " [[6006   82]\n",
      "  [ 364   55]]]\n",
      "transport [[[  78  219]\n",
      "  [  48 6162]]\n",
      "\n",
      " [[6162   48]\n",
      "  [ 219   78]]]\n",
      "buildings [[[ 154  205]\n",
      "  [  74 6074]]\n",
      "\n",
      " [[6074   74]\n",
      "  [ 205  154]]]\n",
      "electricity [[[  34   93]\n",
      "  [  20 6360]]\n",
      "\n",
      " [[6360   20]\n",
      "  [  93   34]]]\n",
      "tools [[[   0   40]\n",
      "  [   7 6460]]\n",
      "\n",
      " [[6460    7]\n",
      "  [  40    0]]]\n",
      "hospitals [[[   5   66]\n",
      "  [  17 6419]]\n",
      "\n",
      " [[6419   17]\n",
      "  [  66    5]]]\n",
      "shops [[[   1   34]\n",
      "  [   2 6470]]\n",
      "\n",
      " [[6470    2]\n",
      "  [  34    1]]]\n",
      "aid_centers [[[   4   68]\n",
      "  [  17 6418]]\n",
      "\n",
      " [[6418   17]\n",
      "  [  68    4]]]\n",
      "other_infrastructure [[[  31  250]\n",
      "  [  52 6174]]\n",
      "\n",
      " [[6174   52]\n",
      "  [ 250   31]]]\n",
      "weather_related [[[1232  582]\n",
      "  [ 187 4506]]\n",
      "\n",
      " [[4506  187]\n",
      "  [ 582 1232]]]\n",
      "floods [[[ 329  205]\n",
      "  [  60 5913]]\n",
      "\n",
      " [[5913   60]\n",
      "  [ 205  329]]]\n",
      "storm [[[ 316  308]\n",
      "  [  98 5785]]\n",
      "\n",
      " [[5785   98]\n",
      "  [ 308  316]]]\n",
      "fire [[[  16   56]\n",
      "  [  14 6421]]\n",
      "\n",
      " [[6421   14]\n",
      "  [  56   16]]]\n",
      "earthquake [[[ 468  138]\n",
      "  [  61 5840]]\n",
      "\n",
      " [[5840   61]\n",
      "  [ 138  468]]]\n",
      "cold [[[  49   91]\n",
      "  [  22 6345]]\n",
      "\n",
      " [[6345   22]\n",
      "  [  91   49]]]\n",
      "other_weather [[[  48  282]\n",
      "  [  59 6118]]\n",
      "\n",
      " [[6118   59]\n",
      "  [ 282   48]]]\n",
      "direct_report [[[ 642  655]\n",
      "  [ 222 4988]]\n",
      "\n",
      " [[4988  222]\n",
      "  [ 655  642]]]\n"
     ]
    }
   ],
   "source": [
    "display_mat(Y_test, y_preds_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StartingVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Returns True/False boolean value for whether the first word in a string of text is a verb or not\n",
    "    '''\n",
    "    def starting_verb(self, text):\n",
    "        pos_tags_dict = {}\n",
    "        for ea_msg in nltk.sent_tokenize(msg):\n",
    "            pos_tags_dict = dict(nltk.pos_tag(tokenize(ea_msg)))\n",
    "            first_word = list(pos_tags_dict.keys())[0]\n",
    "            first_tag = pos_tags_dict[first_word]\n",
    "        #sentence_list = nltk.sent_tokenize(text)\n",
    "        #for sentence in sentence_list:\n",
    "            #pos_tags = nltk.pos_tag(tokenize(sentence))\n",
    "            #first_word, first_tag = pos_tags[0]\n",
    "            if first_tag in ['VB', 'VBP'] or first_word == 'RT':\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "        return pd.DataFrame(X_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline model 4\n",
    "def pipeline_model_4():\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf', TfidfTransformer())\n",
    "            ])),\n",
    "\n",
    "            ('starting_verb', StartingVerbExtractor()),\n",
    "            #(\"word_count\", WordCount()),\n",
    "            #(\"character_count\", CharacterCount()),\n",
    "            #(\"noun_count\", NounCount()),\n",
    "            #(\"verb_count\", VerbCount())\n",
    "        ])),\n",
    "\n",
    "        ('clf', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "    ])\n",
    "    #pipeline = Pipeline([('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    #                      ('tfidf', TfidfTransformer()),\n",
    "    #                      ('clf', MultiOutputClassifier(RandomForestClassifier()))])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = pipeline_model_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_preds_4 = model_4.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35.000000\n",
       "mean      0.940778\n",
       "std       0.057797\n",
       "min       0.754306\n",
       "25%       0.933265\n",
       "50%       0.962092\n",
       "75%       0.979511\n",
       "max       0.993857\n",
       "Name: f1-score, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'lowest quantile of f scores'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.783542</td>\n",
       "      <td>0.801137</td>\n",
       "      <td>0.777111</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.889641</td>\n",
       "      <td>0.896419</td>\n",
       "      <td>0.889729</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.758949</td>\n",
       "      <td>0.759029</td>\n",
       "      <td>0.754306</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.912669</td>\n",
       "      <td>0.926848</td>\n",
       "      <td>0.912353</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.841107</td>\n",
       "      <td>0.872599</td>\n",
       "      <td>0.845232</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.907995</td>\n",
       "      <td>0.931458</td>\n",
       "      <td>0.914852</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.880764</td>\n",
       "      <td>0.881820</td>\n",
       "      <td>0.876986</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.931598</td>\n",
       "      <td>0.937606</td>\n",
       "      <td>0.931841</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.855848</td>\n",
       "      <td>0.865222</td>\n",
       "      <td>0.854408</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision    recall  f1-score  support\n",
       "related                  0.783542  0.801137  0.777111   6507.0\n",
       "request                  0.889641  0.896419  0.889729   6507.0\n",
       "aid_related              0.758949  0.759029  0.754306   6507.0\n",
       "medical_help             0.912669  0.926848  0.912353   6507.0\n",
       "other_aid                0.841107  0.872599  0.845232   6507.0\n",
       "infrastructure_related   0.907995  0.931458  0.914852   6507.0\n",
       "weather_related          0.880764  0.881820  0.876986   6507.0\n",
       "storm                    0.931598  0.937606  0.931841   6507.0\n",
       "direct_report            0.855848  0.865222  0.854408   6507.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'highest quantile of f scores'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.992023</td>\n",
       "      <td>0.995697</td>\n",
       "      <td>0.993857</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.986114</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>0.986604</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.986705</td>\n",
       "      <td>0.989857</td>\n",
       "      <td>0.987283</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.987737</td>\n",
       "      <td>0.992777</td>\n",
       "      <td>0.990250</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.981502</td>\n",
       "      <td>0.987245</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.991215</td>\n",
       "      <td>0.994467</td>\n",
       "      <td>0.992145</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.980675</td>\n",
       "      <td>0.986937</td>\n",
       "      <td>0.983381</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.986094</td>\n",
       "      <td>0.989089</td>\n",
       "      <td>0.986934</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.979498</td>\n",
       "      <td>0.982634</td>\n",
       "      <td>0.979841</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                precision    recall  f1-score  support\n",
       "offer            0.992023  0.995697  0.993857   6507.0\n",
       "clothing         0.986114  0.987859  0.986604   6507.0\n",
       "missing_people   0.986705  0.989857  0.987283   6507.0\n",
       "tools            0.987737  0.992777  0.990250   6507.0\n",
       "hospitals        0.981502  0.987245  0.983908   6507.0\n",
       "shops            0.991215  0.994467  0.992145   6507.0\n",
       "aid_centers      0.980675  0.986937  0.983381   6507.0\n",
       "fire             0.986094  0.989089  0.986934   6507.0\n",
       "cold             0.979498  0.982634  0.979841   6507.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_preds_4 = model_4.predict(X_test)#make predictions\n",
    "wavg_df = metrics_report(Y_test, y_preds_4)\n",
    "display(weighted_avg_report(wavg_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(pipeline, X, Y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y,random_state = 42)\n",
    "    model = pipeline()\n",
    "    y_preds = model.fit(X_train, Y_train)\n",
    "    y_preds = model.predict(X_test)#make predictions\n",
    "    wavg_df = metrics_report(Y_test, y_preds)\n",
    "    display(weighted_avg_report(wavg_df))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY RUNNING A PIPELINE MODEL WITH OBTAINED PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline model 5\n",
    "def pipeline_model_5():\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize, \n",
    "                                         min_df=10\n",
    "                                        )),\n",
    "                ('tfidf', TfidfTransformer(use_idf=True))\n",
    "            ])),\n",
    "\n",
    "            ('starting_verb', StartingVerbExtractor()),\n",
    "        ])),\n",
    "\n",
    "        #('clf', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier(min_samples_split=2, \n",
    "                                                             random_state=42, \n",
    "                                                             n_estimators=100))),\n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    35.000000\n",
       "mean      0.936367\n",
       "std       0.056137\n",
       "min       0.773738\n",
       "25%       0.929425\n",
       "50%       0.952569\n",
       "75%       0.973235\n",
       "max       0.994010\n",
       "Name: f1-score, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'lowest quantile of f scores'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.794633</td>\n",
       "      <td>0.805748</td>\n",
       "      <td>0.773738</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.897481</td>\n",
       "      <td>0.900722</td>\n",
       "      <td>0.889432</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.783533</td>\n",
       "      <td>0.784540</td>\n",
       "      <td>0.782462</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.905547</td>\n",
       "      <td>0.921469</td>\n",
       "      <td>0.893446</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.855229</td>\n",
       "      <td>0.875519</td>\n",
       "      <td>0.825356</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.875306</td>\n",
       "      <td>0.934686</td>\n",
       "      <td>0.904022</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.885076</td>\n",
       "      <td>0.887198</td>\n",
       "      <td>0.885224</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.941519</td>\n",
       "      <td>0.950361</td>\n",
       "      <td>0.928044</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.865105</td>\n",
       "      <td>0.866144</td>\n",
       "      <td>0.845579</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision    recall  f1-score  support\n",
       "related                  0.794633  0.805748  0.773738   6507.0\n",
       "request                  0.897481  0.900722  0.889432   6507.0\n",
       "aid_related              0.783533  0.784540  0.782462   6507.0\n",
       "medical_help             0.905547  0.921469  0.893446   6507.0\n",
       "other_aid                0.855229  0.875519  0.825356   6507.0\n",
       "infrastructure_related   0.875306  0.934686  0.904022   6507.0\n",
       "weather_related          0.885076  0.887198  0.885224   6507.0\n",
       "other_weather            0.941519  0.950361  0.928044   6507.0\n",
       "direct_report            0.865105  0.866144  0.845579   6507.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'highest quantile of f scores'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.992025</td>\n",
       "      <td>0.996004</td>\n",
       "      <td>0.994010</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.983399</td>\n",
       "      <td>0.985861</td>\n",
       "      <td>0.980667</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.989809</td>\n",
       "      <td>0.989703</td>\n",
       "      <td>0.984731</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.979875</td>\n",
       "      <td>0.981558</td>\n",
       "      <td>0.973642</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.987743</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.990789</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.978296</td>\n",
       "      <td>0.989089</td>\n",
       "      <td>0.983663</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.989271</td>\n",
       "      <td>0.994621</td>\n",
       "      <td>0.991939</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.977992</td>\n",
       "      <td>0.988935</td>\n",
       "      <td>0.983433</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.989358</td>\n",
       "      <td>0.989242</td>\n",
       "      <td>0.984183</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                precision    recall  f1-score  support\n",
       "offer            0.992025  0.996004  0.994010   6507.0\n",
       "clothing         0.983399  0.985861  0.980667   6507.0\n",
       "missing_people   0.989809  0.989703  0.984731   6507.0\n",
       "electricity      0.979875  0.981558  0.973642   6507.0\n",
       "tools            0.987743  0.993853  0.990789   6507.0\n",
       "hospitals        0.978296  0.989089  0.983663   6507.0\n",
       "shops            0.989271  0.994621  0.991939   6507.0\n",
       "aid_centers      0.977992  0.988935  0.983433   6507.0\n",
       "fire             0.989358  0.989242  0.984183   6507.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_5 = run_model(pipeline_model_5, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline model 6\n",
    "def pipeline_model_6():\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize, \n",
    "                                         min_df=10\n",
    "                                        )),\n",
    "                ('tfidf', TfidfTransformer(use_idf=True))\n",
    "            ])),\n",
    "\n",
    "            ('starting_verb', StartingVerbExtractor()),\n",
    "        ])),\n",
    "\n",
    "        ('clf', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "        #('clf', MultiOutputClassifier(RandomForestClassifier(min_samples_split=2, \n",
    "                                                             #random_state=42, \n",
    "                                                             #n_estimators=100))),\n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35.000000\n",
       "mean      0.940143\n",
       "std       0.058305\n",
       "min       0.751381\n",
       "25%       0.928964\n",
       "50%       0.960996\n",
       "75%       0.978966\n",
       "max       0.993703\n",
       "Name: f1-score, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'lowest quantile of f scores'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.780339</td>\n",
       "      <td>0.798832</td>\n",
       "      <td>0.774573</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.887983</td>\n",
       "      <td>0.895036</td>\n",
       "      <td>0.887900</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.756138</td>\n",
       "      <td>0.756262</td>\n",
       "      <td>0.751381</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.912740</td>\n",
       "      <td>0.926848</td>\n",
       "      <td>0.912871</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.843370</td>\n",
       "      <td>0.873982</td>\n",
       "      <td>0.846369</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.906537</td>\n",
       "      <td>0.931919</td>\n",
       "      <td>0.913467</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.880345</td>\n",
       "      <td>0.881820</td>\n",
       "      <td>0.877364</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.924548</td>\n",
       "      <td>0.932073</td>\n",
       "      <td>0.922696</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.856269</td>\n",
       "      <td>0.865529</td>\n",
       "      <td>0.854233</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision    recall  f1-score  support\n",
       "related                  0.780339  0.798832  0.774573   6507.0\n",
       "request                  0.887983  0.895036  0.887900   6507.0\n",
       "aid_related              0.756138  0.756262  0.751381   6507.0\n",
       "medical_help             0.912740  0.926848  0.912871   6507.0\n",
       "other_aid                0.843370  0.873982  0.846369   6507.0\n",
       "infrastructure_related   0.906537  0.931919  0.913467   6507.0\n",
       "weather_related          0.880345  0.881820  0.877364   6507.0\n",
       "storm                    0.924548  0.932073  0.922696   6507.0\n",
       "direct_report            0.856269  0.865529  0.854233   6507.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'highest quantile of f scores'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.992022</td>\n",
       "      <td>0.995390</td>\n",
       "      <td>0.993703</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.986024</td>\n",
       "      <td>0.988013</td>\n",
       "      <td>0.986267</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.987621</td>\n",
       "      <td>0.990318</td>\n",
       "      <td>0.987433</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.988915</td>\n",
       "      <td>0.993238</td>\n",
       "      <td>0.990748</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.983352</td>\n",
       "      <td>0.988320</td>\n",
       "      <td>0.984970</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.989267</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.991555</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.981683</td>\n",
       "      <td>0.986630</td>\n",
       "      <td>0.983806</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.987132</td>\n",
       "      <td>0.989857</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.979290</td>\n",
       "      <td>0.982480</td>\n",
       "      <td>0.979717</td>\n",
       "      <td>6507.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                precision    recall  f1-score  support\n",
       "offer            0.992022  0.995390  0.993703   6507.0\n",
       "clothing         0.986024  0.988013  0.986267   6507.0\n",
       "missing_people   0.987621  0.990318  0.987433   6507.0\n",
       "tools            0.988915  0.993238  0.990748   6507.0\n",
       "hospitals        0.983352  0.988320  0.984970   6507.0\n",
       "shops            0.989267  0.993853  0.991555   6507.0\n",
       "aid_centers      0.981683  0.986630  0.983806   6507.0\n",
       "fire             0.987132  0.989857  0.987179   6507.0\n",
       "cold             0.979290  0.982480  0.979717   6507.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_6 = run_model(pipeline_model_6, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'features', 'clf', 'features__n_jobs', 'features__transformer_list', 'features__transformer_weights', 'features__verbose', 'features__text_pipeline', 'features__starting_verb', 'features__text_pipeline__memory', 'features__text_pipeline__steps', 'features__text_pipeline__verbose', 'features__text_pipeline__vect', 'features__text_pipeline__tfidf', 'features__text_pipeline__vect__analyzer', 'features__text_pipeline__vect__binary', 'features__text_pipeline__vect__decode_error', 'features__text_pipeline__vect__dtype', 'features__text_pipeline__vect__encoding', 'features__text_pipeline__vect__input', 'features__text_pipeline__vect__lowercase', 'features__text_pipeline__vect__max_df', 'features__text_pipeline__vect__max_features', 'features__text_pipeline__vect__min_df', 'features__text_pipeline__vect__ngram_range', 'features__text_pipeline__vect__preprocessor', 'features__text_pipeline__vect__stop_words', 'features__text_pipeline__vect__strip_accents', 'features__text_pipeline__vect__token_pattern', 'features__text_pipeline__vect__tokenizer', 'features__text_pipeline__vect__vocabulary', 'features__text_pipeline__tfidf__norm', 'features__text_pipeline__tfidf__smooth_idf', 'features__text_pipeline__tfidf__sublinear_tf', 'features__text_pipeline__tfidf__use_idf', 'clf__estimator__algorithm', 'clf__estimator__base_estimator', 'clf__estimator__learning_rate', 'clf__estimator__n_estimators', 'clf__estimator__random_state', 'clf__estimator', 'clf__n_jobs'])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search\n",
    "\n",
    "parameters_3 = {'vect__min_df': [5, 10],\n",
    "              'clf__estimator__n_estimators':[100, 500, 1000], \n",
    "              'clf__estimator__min_samples_split':[1, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv_3 = GridSearchCV(estimator=model_3, param_grid=parameters_3, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_cv_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model CV 1 best parameters:\n",
    "\n",
    "     {'clf__estimator__min_samples_split': 2,\n",
    "     'clf__estimator__n_estimators': 100,\n",
    "     'tfidf__use_idf': True,\n",
    "     'vect__min_df': 5}\n",
    "\n",
    "model CV 2 best parameters:\n",
    "\n",
    "    {'clf__estimator__min_samples_split': 2,\n",
    "     'clf__estimator__n_estimators': 1000,\n",
    "     'tfidf__use_idf': True,\n",
    "     'vect__binary': False,\n",
    "     'vect__min_df': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F-scores\n",
    "\n",
    "    Model 1:\n",
    "    count    35.000000\n",
    "    mean      0.931140\n",
    "    std       0.057876\n",
    "    min       0.771124\n",
    "    25%       0.916096\n",
    "    50%       0.944198\n",
    "    75%       0.971679\n",
    "    max       0.994010\n",
    "\n",
    "    Model CV 1:\n",
    "    count    9.000000\n",
    "    mean     0.851604\n",
    "    std      0.053219\n",
    "    min      0.771124\n",
    "    25%      0.817647\n",
    "    50%      0.872271\n",
    "    75%      0.883507\n",
    "    max      0.917431\n",
    "\n",
    "    Model 2:\n",
    "    count    35.000000\n",
    "    mean      0.930772\n",
    "    std       0.058746\n",
    "    min       0.767192\n",
    "    25%       0.921509\n",
    "    50%       0.940264\n",
    "    75%       0.970957\n",
    "    max       0.994010\n",
    "\n",
    "    Model CV 2:\n",
    "    count    9.000000\n",
    "    mean     0.859255\n",
    "    std      0.055942\n",
    "    min      0.774758\n",
    "    25%      0.821825\n",
    "    50%      0.887077\n",
    "    75%      0.892294\n",
    "    max      0.933391\n",
    "\n",
    "    Model 3:\n",
    "    count    35.000000\n",
    "    mean      0.940781\n",
    "    std       0.057800\n",
    "    min       0.754306\n",
    "    25%       0.933265\n",
    "    50%       0.962092\n",
    "    75%       0.979511\n",
    "    max       0.993857\n",
    "\n",
    "    Model 4:\n",
    "    count    35.000000\n",
    "    mean      0.940778\n",
    "    std       0.057797\n",
    "    min       0.754306\n",
    "    25%       0.933265\n",
    "    50%       0.962092\n",
    "    75%       0.979511\n",
    "    max       0.993857\n",
    "\n",
    "    Model 5:\n",
    "    count    35.000000\n",
    "    mean      0.936367\n",
    "    std       0.056137\n",
    "    min       0.773738\n",
    "    25%       0.929425\n",
    "    50%       0.952569\n",
    "    75%       0.973235\n",
    "    max       0.994010\n",
    "\n",
    "    Model 6:\n",
    "    count    35.000000\n",
    "    mean      0.940143\n",
    "    std       0.058305\n",
    "    min       0.751381\n",
    "    25%       0.928964\n",
    "    50%       0.960996\n",
    "    75%       0.978966\n",
    "    max       0.993703"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_file(file_to_pickle, file_name):\n",
    "    '''\n",
    "    Saves a file to the data folder with the extension .pkl\n",
    "    file path: '../data/'+ file_name+'.pkl'\n",
    "    '''\n",
    "    pickle.dump(file_to_pickle, open('../data/'+file_name+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 106 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pickle_file(model_3, '../data/model_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pickle_file(model_cv_2, 'model_cv_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'pop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-439-4e3ef5770908>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_cv_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_cv.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-86-0d810b15938c>\u001b[0m in \u001b[0;36mload_pickle\u001b[1;34m(pickled_file_name)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mFile\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'../data/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mpickled_file_name\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.pkl'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     '''\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mpickled_file_name\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m__setstate__\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sklearn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[0mpickle_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_sklearn_version\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pre-0.18\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpickle_version\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                 warnings.warn(\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'pop'"
     ]
    }
   ],
   "source": [
    "model_cv_load = load_pickle('model_cv.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the cross-validation models (which are too big for GitHub anyways) were not able to be saved at the time.  I encountered a bug where the tokenize instance doesn't match the named function, possibly because the function was editing while the tests were running. The summary results are saved as outputs in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file(model_4, 'model_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file(model_5, 'model_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file(model_6, 'model_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(pickled_file_name):\n",
    "    '''\n",
    "    Loads a pickled file (.pkl) in the data folder. \n",
    "    File path: \n",
    "    '''\n",
    "    return pickle.load(open('../data/'+ pickled_file_name+'.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
